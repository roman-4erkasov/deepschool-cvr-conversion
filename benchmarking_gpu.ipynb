{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "44747e9c",
   "metadata": {},
   "source": [
    "# Benchmark of inference tools on GPU\n",
    "\n",
    "Comparisson of different tools for model inference on GPU.\n",
    "\n",
    "|                     |                                         |\n",
    "|---------------------|-------------------------------------------|\n",
    "|**Hard ware**         | Intel Ice Lake with NVIDIA® Tesla® T4 with 4 CPUs and 16 Gb RAM.  |\n",
    "|**Software Platform**| host |\n",
    "|**Tools to compare**| Torch Script, Torch Trace, ONNX, Open Vino|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44238f66",
   "metadata": {},
   "source": [
    "### Common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "77c29c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "353e8880",
   "metadata": {},
   "outputs": [],
   "source": [
    "import timm\n",
    "import torch as th\n",
    "import typing as tp\n",
    "import numpy as np\n",
    "import cv2\n",
    "import yaml\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "from src.utils import get_batch, MAX_UINT8, benchmark\n",
    "\n",
    "\n",
    "DATA_DIR = \"./images\"\n",
    "BATCH_SIZES = [1,2,4,8,16]\n",
    "PLATFORM = \"1GPU\"\n",
    "WARMUP = 5\n",
    "N_RUNS = 10\n",
    "VERBOSE = False\n",
    "N_PRINT = 5\n",
    "DEVICE = \"cuda\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b431cf63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# batches = dict()\n",
    "# for batch_sz in BATCH_SIZES:\n",
    "#     batch = get_batch(DATA_DIR, batch_sz)\n",
    "#     batches[batch_sz] = batch\n",
    "#     del batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "245744dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_records = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3a6f16a",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Torch Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b7f23763",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.model.torch import ModelTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "92efe23b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>platform</th>\n",
       "      <th>batch_sz</th>\n",
       "      <th>tool</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.039822</td>\n",
       "      <td>1GPU</td>\n",
       "      <td>1</td>\n",
       "      <td>Torch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.064748</td>\n",
       "      <td>1GPU</td>\n",
       "      <td>2</td>\n",
       "      <td>Torch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.134212</td>\n",
       "      <td>1GPU</td>\n",
       "      <td>4</td>\n",
       "      <td>Torch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.263537</td>\n",
       "      <td>1GPU</td>\n",
       "      <td>8</td>\n",
       "      <td>Torch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.543216</td>\n",
       "      <td>1GPU</td>\n",
       "      <td>16</td>\n",
       "      <td>Torch</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       time platform  batch_sz   tool\n",
       "0  0.039822     1GPU         1  Torch\n",
       "1  0.064748     1GPU         2  Torch\n",
       "2  0.134212     1GPU         4  Torch\n",
       "3  0.263537     1GPU         8  Torch\n",
       "4  0.543216     1GPU        16  Torch"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "records = []\n",
    "with open(\"./config/torch.yaml\") as fp:\n",
    "    cfg_torch = yaml.safe_load(fp)\n",
    "\n",
    "cfg_torch[\"device\"] = DEVICE\n",
    "model_torch = ModelTorch(cfg_torch)\n",
    "for batch_sz in BATCH_SIZES:\n",
    "    avg, stdev = benchmark(\n",
    "        model=model_torch,\n",
    "        input_shape=(batch_sz, 3, MAX_UINT8, MAX_UINT8),\n",
    "        nwarmup=WARMUP,\n",
    "        nruns=N_RUNS,\n",
    "        print_step=N_PRINT,\n",
    "        verbose=VERBOSE\n",
    "    )\n",
    "    records.append(\n",
    "        {\n",
    "            \"time\": avg,\n",
    "            \"platform\": PLATFORM, \n",
    "            \"batch_sz\": batch_sz,\n",
    "            \"tool\": \"Torch\"\n",
    "        }\n",
    "    )\n",
    "inference_records.extend(records)\n",
    "pd.DataFrame(records)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31bce913",
   "metadata": {
    "tags": []
   },
   "source": [
    "### TorchScript Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0e3ccb1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fatuus/deepschool-cvr-conversion/venv/lib/python3.8/site-packages/torch/nn/modules/module.py:1501: UserWarning: operator() profile_node %833 : bool = prim::profile_ivalue(%training.11)\n",
      " does not have profile information (Triggered internally at ../third_party/nvfuser/csrc/graph_fuser.cpp:104.)\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>platform</th>\n",
       "      <th>batch_sz</th>\n",
       "      <th>tool</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.004247</td>\n",
       "      <td>1GPU</td>\n",
       "      <td>1</td>\n",
       "      <td>TorchScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.005525</td>\n",
       "      <td>1GPU</td>\n",
       "      <td>2</td>\n",
       "      <td>TorchScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.007880</td>\n",
       "      <td>1GPU</td>\n",
       "      <td>4</td>\n",
       "      <td>TorchScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.010182</td>\n",
       "      <td>1GPU</td>\n",
       "      <td>8</td>\n",
       "      <td>TorchScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.015301</td>\n",
       "      <td>1GPU</td>\n",
       "      <td>16</td>\n",
       "      <td>TorchScript</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       time platform  batch_sz         tool\n",
       "0  0.004247     1GPU         1  TorchScript\n",
       "1  0.005525     1GPU         2  TorchScript\n",
       "2  0.007880     1GPU         4  TorchScript\n",
       "3  0.010182     1GPU         8  TorchScript\n",
       "4  0.015301     1GPU        16  TorchScript"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.model.torch_jit import ModelTorchJIT\n",
    "\n",
    "tmp = th.jit.script(model_torch.model)\n",
    "th.jit.save(tmp, \"weights/model_scripted.th\")\n",
    "\n",
    "with open(\"./config/torch_scripted.yaml\") as fp:\n",
    "    cfg_scripted = yaml.safe_load(fp)\n",
    "cfg_scripted[\"device\"] = \"cuda\"\n",
    "model_scripted = ModelTorchJIT(cfg_scripted)\n",
    "records = []\n",
    "for batch_sz in BATCH_SIZES:\n",
    "    avg, stdev = benchmark(\n",
    "        model=model_scripted,\n",
    "        input_shape=(batch_sz, 3, MAX_UINT8, MAX_UINT8),\n",
    "        nwarmup=WARMUP,\n",
    "        nruns=N_RUNS,\n",
    "        print_step=N_PRINT,\n",
    "        verbose=VERBOSE\n",
    "    )\n",
    "    records.append(\n",
    "        {\n",
    "            \"time\": avg,\n",
    "            \"platform\": PLATFORM, \n",
    "            \"batch_sz\": batch_sz,\n",
    "            \"tool\": \"TorchScript\"\n",
    "        }\n",
    "    )\n",
    "inference_records.extend(records)\n",
    "pd.DataFrame(records)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "440bede6",
   "metadata": {
    "tags": []
   },
   "source": [
    "### TorchTrace Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "23bc44ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.model.torch_jit import ModelTorchJIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fec47a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = th.jit.trace(\n",
    "    model_torch.model,\n",
    "    th.rand(1, 3, MAX_UINT8, MAX_UINT8).to(th.float32)\n",
    ")\n",
    "th.jit.save(tmp, \"weights/model_traced.th\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "66143c9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>platform</th>\n",
       "      <th>batch_sz</th>\n",
       "      <th>tool</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.004196</td>\n",
       "      <td>1GPU</td>\n",
       "      <td>1</td>\n",
       "      <td>TorchTrace</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.005484</td>\n",
       "      <td>1GPU</td>\n",
       "      <td>2</td>\n",
       "      <td>TorchTrace</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.008852</td>\n",
       "      <td>1GPU</td>\n",
       "      <td>4</td>\n",
       "      <td>TorchTrace</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.010419</td>\n",
       "      <td>1GPU</td>\n",
       "      <td>8</td>\n",
       "      <td>TorchTrace</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.015768</td>\n",
       "      <td>1GPU</td>\n",
       "      <td>16</td>\n",
       "      <td>TorchTrace</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       time platform  batch_sz        tool\n",
       "0  0.004196     1GPU         1  TorchTrace\n",
       "1  0.005484     1GPU         2  TorchTrace\n",
       "2  0.008852     1GPU         4  TorchTrace\n",
       "3  0.010419     1GPU         8  TorchTrace\n",
       "4  0.015768     1GPU        16  TorchTrace"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"./config/torch_traced.yaml\") as fp:\n",
    "    cfg_traced = yaml.safe_load(fp)\n",
    "cfg_traced[\"device\"] = DEVICE\n",
    "model_traced = ModelTorchJIT(cfg_traced)\n",
    "records = []\n",
    "for batch_sz in BATCH_SIZES:\n",
    "    avg, _=benchmark(\n",
    "        model=model_traced,\n",
    "        input_shape=(batch_sz, 3, MAX_UINT8, MAX_UINT8),\n",
    "        nwarmup=WARMUP,\n",
    "        nruns=N_RUNS,\n",
    "        print_step=N_PRINT,\n",
    "        verbose=VERBOSE\n",
    "    )\n",
    "    records.append(\n",
    "        {\n",
    "            \"time\": avg,\n",
    "            \"platform\": PLATFORM, \n",
    "            \"batch_sz\": batch_sz,\n",
    "            \"tool\": \"TorchTrace\"\n",
    "        }\n",
    "    )\n",
    "inference_records.extend(records)\n",
    "pd.DataFrame(records)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "410dbb9e",
   "metadata": {},
   "source": [
    "### ONNX Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "50c21f1e-61f0-4f80-87f7-1182f8fdd6cf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ort.get_available_providers()=['TensorrtExecutionProvider', 'CUDAExecutionProvider', 'CPUExecutionProvider']\n"
     ]
    }
   ],
   "source": [
    "import onnxruntime as ort\n",
    "print(f\"{ort.get_available_providers()=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "794ecac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.model.onnx import ModelONNX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ebaeb44c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fatuus/deepschool-cvr-conversion/venv/lib/python3.8/site-packages/torch/onnx/utils.py:2033: UserWarning: No names were found for specified dynamic axes of provided input.Automatically generated names will be applied to each dynamic axes of input input\n",
      "  warnings.warn(\n",
      "/home/fatuus/deepschool-cvr-conversion/venv/lib/python3.8/site-packages/torch/onnx/utils.py:2033: UserWarning: No names were found for specified dynamic axes of provided input.Automatically generated names will be applied to each dynamic axes of input output\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exported graph: graph(%input : Float(*, 3, 255, 255, strides=[195075, 65025, 255, 1], requires_grad=0, device=cpu),\n",
      "      %fc.weight : Float(17, 512, strides=[512, 1], requires_grad=1, device=cpu),\n",
      "      %fc.bias : Float(17, strides=[1], requires_grad=1, device=cpu),\n",
      "      %onnx::Conv_193 : Float(64, 3, 7, 7, strides=[147, 49, 7, 1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_194 : Float(64, strides=[1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_196 : Float(64, 64, 3, 3, strides=[576, 9, 3, 1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_197 : Float(64, strides=[1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_199 : Float(64, 64, 3, 3, strides=[576, 9, 3, 1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_200 : Float(64, strides=[1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_202 : Float(64, 64, 3, 3, strides=[576, 9, 3, 1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_203 : Float(64, strides=[1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_205 : Float(64, 64, 3, 3, strides=[576, 9, 3, 1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_206 : Float(64, strides=[1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_208 : Float(128, 64, 3, 3, strides=[576, 9, 3, 1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_209 : Float(128, strides=[1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_211 : Float(128, 128, 3, 3, strides=[1152, 9, 3, 1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_212 : Float(128, strides=[1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_214 : Float(128, 64, 1, 1, strides=[64, 1, 1, 1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_215 : Float(128, strides=[1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_217 : Float(128, 128, 3, 3, strides=[1152, 9, 3, 1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_218 : Float(128, strides=[1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_220 : Float(128, 128, 3, 3, strides=[1152, 9, 3, 1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_221 : Float(128, strides=[1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_223 : Float(256, 128, 3, 3, strides=[1152, 9, 3, 1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_224 : Float(256, strides=[1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_226 : Float(256, 256, 3, 3, strides=[2304, 9, 3, 1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_227 : Float(256, strides=[1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_229 : Float(256, 128, 1, 1, strides=[128, 1, 1, 1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_230 : Float(256, strides=[1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_232 : Float(256, 256, 3, 3, strides=[2304, 9, 3, 1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_233 : Float(256, strides=[1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_235 : Float(256, 256, 3, 3, strides=[2304, 9, 3, 1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_236 : Float(256, strides=[1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_238 : Float(512, 256, 3, 3, strides=[2304, 9, 3, 1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_239 : Float(512, strides=[1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_241 : Float(512, 512, 3, 3, strides=[4608, 9, 3, 1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_242 : Float(512, strides=[1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_244 : Float(512, 256, 1, 1, strides=[256, 1, 1, 1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_245 : Float(512, strides=[1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_247 : Float(512, 512, 3, 3, strides=[4608, 9, 3, 1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_248 : Float(512, strides=[1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_250 : Float(512, 512, 3, 3, strides=[4608, 9, 3, 1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_251 : Float(512, strides=[1], requires_grad=0, device=cpu)):\n",
      "  %/conv1/Conv_output_0 : Float(*, 64, 128, 128, strides=[1048576, 16384, 128, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[7, 7], pads=[3, 3, 3, 3], strides=[2, 2], onnx_name=\"/conv1/Conv\"](%input, %onnx::Conv_193, %onnx::Conv_194), scope: timm.models.resnet.ResNet::/torch.nn.modules.conv.Conv2d::conv1 # /home/fatuus/deepschool-cvr-conversion/venv/lib/python3.8/site-packages/torch/nn/modules/conv.py:459:0\n",
      "  %/act1/Relu_output_0 : Float(*, 64, 128, 128, strides=[1048576, 16384, 128, 1], requires_grad=1, device=cpu) = onnx::Relu[onnx_name=\"/act1/Relu\"](%/conv1/Conv_output_0), scope: timm.models.resnet.ResNet::/torch.nn.modules.activation.ReLU::act1 # /home/fatuus/deepschool-cvr-conversion/venv/lib/python3.8/site-packages/torch/nn/functional.py:1455:0\n",
      "  %/maxpool/MaxPool_output_0 : Float(*, 64, 64, 64, strides=[262144, 4096, 64, 1], requires_grad=1, device=cpu) = onnx::MaxPool[ceil_mode=0, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[2, 2], onnx_name=\"/maxpool/MaxPool\"](%/act1/Relu_output_0), scope: timm.models.resnet.ResNet::/torch.nn.modules.pooling.MaxPool2d::maxpool # /home/fatuus/deepschool-cvr-conversion/venv/lib/python3.8/site-packages/torch/nn/functional.py:782:0\n",
      "  %/layer1/layer1.0/conv1/Conv_output_0 : Float(*, 64, 64, 64, strides=[262144, 4096, 64, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name=\"/layer1/layer1.0/conv1/Conv\"](%/maxpool/MaxPool_output_0, %onnx::Conv_196, %onnx::Conv_197), scope: timm.models.resnet.ResNet::/torch.nn.modules.container.Sequential::layer1/timm.models.resnet.BasicBlock::layer1.0/torch.nn.modules.conv.Conv2d::conv1 # /home/fatuus/deepschool-cvr-conversion/venv/lib/python3.8/site-packages/torch/nn/modules/conv.py:459:0\n",
      "  %/layer1/layer1.0/act1/Relu_output_0 : Float(*, 64, 64, 64, strides=[262144, 4096, 64, 1], requires_grad=1, device=cpu) = onnx::Relu[onnx_name=\"/layer1/layer1.0/act1/Relu\"](%/layer1/layer1.0/conv1/Conv_output_0), scope: timm.models.resnet.ResNet::/torch.nn.modules.container.Sequential::layer1/timm.models.resnet.BasicBlock::layer1.0/torch.nn.modules.activation.ReLU::act1 # /home/fatuus/deepschool-cvr-conversion/venv/lib/python3.8/site-packages/torch/nn/functional.py:1455:0\n",
      "  %/layer1/layer1.0/conv2/Conv_output_0 : Float(*, 64, 64, 64, strides=[262144, 4096, 64, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name=\"/layer1/layer1.0/conv2/Conv\"](%/layer1/layer1.0/act1/Relu_output_0, %onnx::Conv_199, %onnx::Conv_200), scope: timm.models.resnet.ResNet::/torch.nn.modules.container.Sequential::layer1/timm.models.resnet.BasicBlock::layer1.0/torch.nn.modules.conv.Conv2d::conv2 # /home/fatuus/deepschool-cvr-conversion/venv/lib/python3.8/site-packages/torch/nn/modules/conv.py:459:0\n",
      "  %/layer1/layer1.0/Add_output_0 : Float(*, 64, 64, 64, strides=[262144, 4096, 64, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"/layer1/layer1.0/Add\"](%/layer1/layer1.0/conv2/Conv_output_0, %/maxpool/MaxPool_output_0), scope: timm.models.resnet.ResNet::/torch.nn.modules.container.Sequential::layer1/timm.models.resnet.BasicBlock::layer1.0 # /home/fatuus/deepschool-cvr-conversion/venv/lib/python3.8/site-packages/timm/models/resnet.py:344:0\n",
      "  %/layer1/layer1.0/act2/Relu_output_0 : Float(*, 64, 64, 64, strides=[262144, 4096, 64, 1], requires_grad=1, device=cpu) = onnx::Relu[onnx_name=\"/layer1/layer1.0/act2/Relu\"](%/layer1/layer1.0/Add_output_0), scope: timm.models.resnet.ResNet::/torch.nn.modules.container.Sequential::layer1/timm.models.resnet.BasicBlock::layer1.0/torch.nn.modules.activation.ReLU::act2 # /home/fatuus/deepschool-cvr-conversion/venv/lib/python3.8/site-packages/torch/nn/functional.py:1455:0\n",
      "  %/layer1/layer1.1/conv1/Conv_output_0 : Float(*, 64, 64, 64, strides=[262144, 4096, 64, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name=\"/layer1/layer1.1/conv1/Conv\"](%/layer1/layer1.0/act2/Relu_output_0, %onnx::Conv_202, %onnx::Conv_203), scope: timm.models.resnet.ResNet::/torch.nn.modules.container.Sequential::layer1/timm.models.resnet.BasicBlock::layer1.1/torch.nn.modules.conv.Conv2d::conv1 # /home/fatuus/deepschool-cvr-conversion/venv/lib/python3.8/site-packages/torch/nn/modules/conv.py:459:0\n",
      "  %/layer1/layer1.1/act1/Relu_output_0 : Float(*, 64, 64, 64, strides=[262144, 4096, 64, 1], requires_grad=1, device=cpu) = onnx::Relu[onnx_name=\"/layer1/layer1.1/act1/Relu\"](%/layer1/layer1.1/conv1/Conv_output_0), scope: timm.models.resnet.ResNet::/torch.nn.modules.container.Sequential::layer1/timm.models.resnet.BasicBlock::layer1.1/torch.nn.modules.activation.ReLU::act1 # /home/fatuus/deepschool-cvr-conversion/venv/lib/python3.8/site-packages/torch/nn/functional.py:1455:0\n",
      "  %/layer1/layer1.1/conv2/Conv_output_0 : Float(*, 64, 64, 64, strides=[262144, 4096, 64, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name=\"/layer1/layer1.1/conv2/Conv\"](%/layer1/layer1.1/act1/Relu_output_0, %onnx::Conv_205, %onnx::Conv_206), scope: timm.models.resnet.ResNet::/torch.nn.modules.container.Sequential::layer1/timm.models.resnet.BasicBlock::layer1.1/torch.nn.modules.conv.Conv2d::conv2 # /home/fatuus/deepschool-cvr-conversion/venv/lib/python3.8/site-packages/torch/nn/modules/conv.py:459:0\n",
      "  %/layer1/layer1.1/Add_output_0 : Float(*, 64, 64, 64, strides=[262144, 4096, 64, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"/layer1/layer1.1/Add\"](%/layer1/layer1.1/conv2/Conv_output_0, %/layer1/layer1.0/act2/Relu_output_0), scope: timm.models.resnet.ResNet::/torch.nn.modules.container.Sequential::layer1/timm.models.resnet.BasicBlock::layer1.1 # /home/fatuus/deepschool-cvr-conversion/venv/lib/python3.8/site-packages/timm/models/resnet.py:344:0\n",
      "  %/layer1/layer1.1/act2/Relu_output_0 : Float(*, 64, 64, 64, strides=[262144, 4096, 64, 1], requires_grad=1, device=cpu) = onnx::Relu[onnx_name=\"/layer1/layer1.1/act2/Relu\"](%/layer1/layer1.1/Add_output_0), scope: timm.models.resnet.ResNet::/torch.nn.modules.container.Sequential::layer1/timm.models.resnet.BasicBlock::layer1.1/torch.nn.modules.activation.ReLU::act2 # /home/fatuus/deepschool-cvr-conversion/venv/lib/python3.8/site-packages/torch/nn/functional.py:1455:0\n",
      "  %/layer2/layer2.0/conv1/Conv_output_0 : Float(*, 128, 32, 32, strides=[131072, 1024, 32, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[2, 2], onnx_name=\"/layer2/layer2.0/conv1/Conv\"](%/layer1/layer1.1/act2/Relu_output_0, %onnx::Conv_208, %onnx::Conv_209), scope: timm.models.resnet.ResNet::/torch.nn.modules.container.Sequential::layer2/timm.models.resnet.BasicBlock::layer2.0/torch.nn.modules.conv.Conv2d::conv1 # /home/fatuus/deepschool-cvr-conversion/venv/lib/python3.8/site-packages/torch/nn/modules/conv.py:459:0\n",
      "  %/layer2/layer2.0/act1/Relu_output_0 : Float(*, 128, 32, 32, strides=[131072, 1024, 32, 1], requires_grad=1, device=cpu) = onnx::Relu[onnx_name=\"/layer2/layer2.0/act1/Relu\"](%/layer2/layer2.0/conv1/Conv_output_0), scope: timm.models.resnet.ResNet::/torch.nn.modules.container.Sequential::layer2/timm.models.resnet.BasicBlock::layer2.0/torch.nn.modules.activation.ReLU::act1 # /home/fatuus/deepschool-cvr-conversion/venv/lib/python3.8/site-packages/torch/nn/functional.py:1455:0\n",
      "  %/layer2/layer2.0/conv2/Conv_output_0 : Float(*, 128, 32, 32, strides=[131072, 1024, 32, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name=\"/layer2/layer2.0/conv2/Conv\"](%/layer2/layer2.0/act1/Relu_output_0, %onnx::Conv_211, %onnx::Conv_212), scope: timm.models.resnet.ResNet::/torch.nn.modules.container.Sequential::layer2/timm.models.resnet.BasicBlock::layer2.0/torch.nn.modules.conv.Conv2d::conv2 # /home/fatuus/deepschool-cvr-conversion/venv/lib/python3.8/site-packages/torch/nn/modules/conv.py:459:0\n",
      "  %/layer2/layer2.0/downsample/downsample.0/Conv_output_0 : Float(*, 128, 32, 32, strides=[131072, 1024, 32, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[2, 2], onnx_name=\"/layer2/layer2.0/downsample/downsample.0/Conv\"](%/layer1/layer1.1/act2/Relu_output_0, %onnx::Conv_214, %onnx::Conv_215), scope: timm.models.resnet.ResNet::/torch.nn.modules.container.Sequential::layer2/timm.models.resnet.BasicBlock::layer2.0/torch.nn.modules.container.Sequential::downsample/torch.nn.modules.conv.Conv2d::downsample.0 # /home/fatuus/deepschool-cvr-conversion/venv/lib/python3.8/site-packages/torch/nn/modules/conv.py:459:0\n",
      "  %/layer2/layer2.0/Add_output_0 : Float(*, 128, 32, 32, strides=[131072, 1024, 32, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"/layer2/layer2.0/Add\"](%/layer2/layer2.0/conv2/Conv_output_0, %/layer2/layer2.0/downsample/downsample.0/Conv_output_0), scope: timm.models.resnet.ResNet::/torch.nn.modules.container.Sequential::layer2/timm.models.resnet.BasicBlock::layer2.0 # /home/fatuus/deepschool-cvr-conversion/venv/lib/python3.8/site-packages/timm/models/resnet.py:344:0\n",
      "  %/layer2/layer2.0/act2/Relu_output_0 : Float(*, 128, 32, 32, strides=[131072, 1024, 32, 1], requires_grad=1, device=cpu) = onnx::Relu[onnx_name=\"/layer2/layer2.0/act2/Relu\"](%/layer2/layer2.0/Add_output_0), scope: timm.models.resnet.ResNet::/torch.nn.modules.container.Sequential::layer2/timm.models.resnet.BasicBlock::layer2.0/torch.nn.modules.activation.ReLU::act2 # /home/fatuus/deepschool-cvr-conversion/venv/lib/python3.8/site-packages/torch/nn/functional.py:1455:0\n",
      "  %/layer2/layer2.1/conv1/Conv_output_0 : Float(*, 128, 32, 32, strides=[131072, 1024, 32, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name=\"/layer2/layer2.1/conv1/Conv\"](%/layer2/layer2.0/act2/Relu_output_0, %onnx::Conv_217, %onnx::Conv_218), scope: timm.models.resnet.ResNet::/torch.nn.modules.container.Sequential::layer2/timm.models.resnet.BasicBlock::layer2.1/torch.nn.modules.conv.Conv2d::conv1 # /home/fatuus/deepschool-cvr-conversion/venv/lib/python3.8/site-packages/torch/nn/modules/conv.py:459:0\n",
      "  %/layer2/layer2.1/act1/Relu_output_0 : Float(*, 128, 32, 32, strides=[131072, 1024, 32, 1], requires_grad=1, device=cpu) = onnx::Relu[onnx_name=\"/layer2/layer2.1/act1/Relu\"](%/layer2/layer2.1/conv1/Conv_output_0), scope: timm.models.resnet.ResNet::/torch.nn.modules.container.Sequential::layer2/timm.models.resnet.BasicBlock::layer2.1/torch.nn.modules.activation.ReLU::act1 # /home/fatuus/deepschool-cvr-conversion/venv/lib/python3.8/site-packages/torch/nn/functional.py:1455:0\n",
      "  %/layer2/layer2.1/conv2/Conv_output_0 : Float(*, 128, 32, 32, strides=[131072, 1024, 32, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name=\"/layer2/layer2.1/conv2/Conv\"](%/layer2/layer2.1/act1/Relu_output_0, %onnx::Conv_220, %onnx::Conv_221), scope: timm.models.resnet.ResNet::/torch.nn.modules.container.Sequential::layer2/timm.models.resnet.BasicBlock::layer2.1/torch.nn.modules.conv.Conv2d::conv2 # /home/fatuus/deepschool-cvr-conversion/venv/lib/python3.8/site-packages/torch/nn/modules/conv.py:459:0\n",
      "  %/layer2/layer2.1/Add_output_0 : Float(*, 128, 32, 32, strides=[131072, 1024, 32, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"/layer2/layer2.1/Add\"](%/layer2/layer2.1/conv2/Conv_output_0, %/layer2/layer2.0/act2/Relu_output_0), scope: timm.models.resnet.ResNet::/torch.nn.modules.container.Sequential::layer2/timm.models.resnet.BasicBlock::layer2.1 # /home/fatuus/deepschool-cvr-conversion/venv/lib/python3.8/site-packages/timm/models/resnet.py:344:0\n",
      "  %/layer2/layer2.1/act2/Relu_output_0 : Float(*, 128, 32, 32, strides=[131072, 1024, 32, 1], requires_grad=1, device=cpu) = onnx::Relu[onnx_name=\"/layer2/layer2.1/act2/Relu\"](%/layer2/layer2.1/Add_output_0), scope: timm.models.resnet.ResNet::/torch.nn.modules.container.Sequential::layer2/timm.models.resnet.BasicBlock::layer2.1/torch.nn.modules.activation.ReLU::act2 # /home/fatuus/deepschool-cvr-conversion/venv/lib/python3.8/site-packages/torch/nn/functional.py:1455:0\n",
      "  %/layer3/layer3.0/conv1/Conv_output_0 : Float(*, 256, 16, 16, strides=[65536, 256, 16, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[2, 2], onnx_name=\"/layer3/layer3.0/conv1/Conv\"](%/layer2/layer2.1/act2/Relu_output_0, %onnx::Conv_223, %onnx::Conv_224), scope: timm.models.resnet.ResNet::/torch.nn.modules.container.Sequential::layer3/timm.models.resnet.BasicBlock::layer3.0/torch.nn.modules.conv.Conv2d::conv1 # /home/fatuus/deepschool-cvr-conversion/venv/lib/python3.8/site-packages/torch/nn/modules/conv.py:459:0\n",
      "  %/layer3/layer3.0/act1/Relu_output_0 : Float(*, 256, 16, 16, strides=[65536, 256, 16, 1], requires_grad=1, device=cpu) = onnx::Relu[onnx_name=\"/layer3/layer3.0/act1/Relu\"](%/layer3/layer3.0/conv1/Conv_output_0), scope: timm.models.resnet.ResNet::/torch.nn.modules.container.Sequential::layer3/timm.models.resnet.BasicBlock::layer3.0/torch.nn.modules.activation.ReLU::act1 # /home/fatuus/deepschool-cvr-conversion/venv/lib/python3.8/site-packages/torch/nn/functional.py:1455:0\n",
      "  %/layer3/layer3.0/conv2/Conv_output_0 : Float(*, 256, 16, 16, strides=[65536, 256, 16, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name=\"/layer3/layer3.0/conv2/Conv\"](%/layer3/layer3.0/act1/Relu_output_0, %onnx::Conv_226, %onnx::Conv_227), scope: timm.models.resnet.ResNet::/torch.nn.modules.container.Sequential::layer3/timm.models.resnet.BasicBlock::layer3.0/torch.nn.modules.conv.Conv2d::conv2 # /home/fatuus/deepschool-cvr-conversion/venv/lib/python3.8/site-packages/torch/nn/modules/conv.py:459:0\n",
      "  %/layer3/layer3.0/downsample/downsample.0/Conv_output_0 : Float(*, 256, 16, 16, strides=[65536, 256, 16, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[2, 2], onnx_name=\"/layer3/layer3.0/downsample/downsample.0/Conv\"](%/layer2/layer2.1/act2/Relu_output_0, %onnx::Conv_229, %onnx::Conv_230), scope: timm.models.resnet.ResNet::/torch.nn.modules.container.Sequential::layer3/timm.models.resnet.BasicBlock::layer3.0/torch.nn.modules.container.Sequential::downsample/torch.nn.modules.conv.Conv2d::downsample.0 # /home/fatuus/deepschool-cvr-conversion/venv/lib/python3.8/site-packages/torch/nn/modules/conv.py:459:0\n",
      "  %/layer3/layer3.0/Add_output_0 : Float(*, 256, 16, 16, strides=[65536, 256, 16, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"/layer3/layer3.0/Add\"](%/layer3/layer3.0/conv2/Conv_output_0, %/layer3/layer3.0/downsample/downsample.0/Conv_output_0), scope: timm.models.resnet.ResNet::/torch.nn.modules.container.Sequential::layer3/timm.models.resnet.BasicBlock::layer3.0 # /home/fatuus/deepschool-cvr-conversion/venv/lib/python3.8/site-packages/timm/models/resnet.py:344:0\n",
      "  %/layer3/layer3.0/act2/Relu_output_0 : Float(*, 256, 16, 16, strides=[65536, 256, 16, 1], requires_grad=1, device=cpu) = onnx::Relu[onnx_name=\"/layer3/layer3.0/act2/Relu\"](%/layer3/layer3.0/Add_output_0), scope: timm.models.resnet.ResNet::/torch.nn.modules.container.Sequential::layer3/timm.models.resnet.BasicBlock::layer3.0/torch.nn.modules.activation.ReLU::act2 # /home/fatuus/deepschool-cvr-conversion/venv/lib/python3.8/site-packages/torch/nn/functional.py:1455:0\n",
      "  %/layer3/layer3.1/conv1/Conv_output_0 : Float(*, 256, 16, 16, strides=[65536, 256, 16, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name=\"/layer3/layer3.1/conv1/Conv\"](%/layer3/layer3.0/act2/Relu_output_0, %onnx::Conv_232, %onnx::Conv_233), scope: timm.models.resnet.ResNet::/torch.nn.modules.container.Sequential::layer3/timm.models.resnet.BasicBlock::layer3.1/torch.nn.modules.conv.Conv2d::conv1 # /home/fatuus/deepschool-cvr-conversion/venv/lib/python3.8/site-packages/torch/nn/modules/conv.py:459:0\n",
      "  %/layer3/layer3.1/act1/Relu_output_0 : Float(*, 256, 16, 16, strides=[65536, 256, 16, 1], requires_grad=1, device=cpu) = onnx::Relu[onnx_name=\"/layer3/layer3.1/act1/Relu\"](%/layer3/layer3.1/conv1/Conv_output_0), scope: timm.models.resnet.ResNet::/torch.nn.modules.container.Sequential::layer3/timm.models.resnet.BasicBlock::layer3.1/torch.nn.modules.activation.ReLU::act1 # /home/fatuus/deepschool-cvr-conversion/venv/lib/python3.8/site-packages/torch/nn/functional.py:1455:0\n",
      "  %/layer3/layer3.1/conv2/Conv_output_0 : Float(*, 256, 16, 16, strides=[65536, 256, 16, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name=\"/layer3/layer3.1/conv2/Conv\"](%/layer3/layer3.1/act1/Relu_output_0, %onnx::Conv_235, %onnx::Conv_236), scope: timm.models.resnet.ResNet::/torch.nn.modules.container.Sequential::layer3/timm.models.resnet.BasicBlock::layer3.1/torch.nn.modules.conv.Conv2d::conv2 # /home/fatuus/deepschool-cvr-conversion/venv/lib/python3.8/site-packages/torch/nn/modules/conv.py:459:0\n",
      "  %/layer3/layer3.1/Add_output_0 : Float(*, 256, 16, 16, strides=[65536, 256, 16, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"/layer3/layer3.1/Add\"](%/layer3/layer3.1/conv2/Conv_output_0, %/layer3/layer3.0/act2/Relu_output_0), scope: timm.models.resnet.ResNet::/torch.nn.modules.container.Sequential::layer3/timm.models.resnet.BasicBlock::layer3.1 # /home/fatuus/deepschool-cvr-conversion/venv/lib/python3.8/site-packages/timm/models/resnet.py:344:0\n",
      "  %/layer3/layer3.1/act2/Relu_output_0 : Float(*, 256, 16, 16, strides=[65536, 256, 16, 1], requires_grad=1, device=cpu) = onnx::Relu[onnx_name=\"/layer3/layer3.1/act2/Relu\"](%/layer3/layer3.1/Add_output_0), scope: timm.models.resnet.ResNet::/torch.nn.modules.container.Sequential::layer3/timm.models.resnet.BasicBlock::layer3.1/torch.nn.modules.activation.ReLU::act2 # /home/fatuus/deepschool-cvr-conversion/venv/lib/python3.8/site-packages/torch/nn/functional.py:1455:0\n",
      "  %/layer4/layer4.0/conv1/Conv_output_0 : Float(*, 512, 8, 8, strides=[32768, 64, 8, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[2, 2], onnx_name=\"/layer4/layer4.0/conv1/Conv\"](%/layer3/layer3.1/act2/Relu_output_0, %onnx::Conv_238, %onnx::Conv_239), scope: timm.models.resnet.ResNet::/torch.nn.modules.container.Sequential::layer4/timm.models.resnet.BasicBlock::layer4.0/torch.nn.modules.conv.Conv2d::conv1 # /home/fatuus/deepschool-cvr-conversion/venv/lib/python3.8/site-packages/torch/nn/modules/conv.py:459:0\n",
      "  %/layer4/layer4.0/act1/Relu_output_0 : Float(*, 512, 8, 8, strides=[32768, 64, 8, 1], requires_grad=1, device=cpu) = onnx::Relu[onnx_name=\"/layer4/layer4.0/act1/Relu\"](%/layer4/layer4.0/conv1/Conv_output_0), scope: timm.models.resnet.ResNet::/torch.nn.modules.container.Sequential::layer4/timm.models.resnet.BasicBlock::layer4.0/torch.nn.modules.activation.ReLU::act1 # /home/fatuus/deepschool-cvr-conversion/venv/lib/python3.8/site-packages/torch/nn/functional.py:1455:0\n",
      "  %/layer4/layer4.0/conv2/Conv_output_0 : Float(*, 512, 8, 8, strides=[32768, 64, 8, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name=\"/layer4/layer4.0/conv2/Conv\"](%/layer4/layer4.0/act1/Relu_output_0, %onnx::Conv_241, %onnx::Conv_242), scope: timm.models.resnet.ResNet::/torch.nn.modules.container.Sequential::layer4/timm.models.resnet.BasicBlock::layer4.0/torch.nn.modules.conv.Conv2d::conv2 # /home/fatuus/deepschool-cvr-conversion/venv/lib/python3.8/site-packages/torch/nn/modules/conv.py:459:0\n",
      "  %/layer4/layer4.0/downsample/downsample.0/Conv_output_0 : Float(*, 512, 8, 8, strides=[32768, 64, 8, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[2, 2], onnx_name=\"/layer4/layer4.0/downsample/downsample.0/Conv\"](%/layer3/layer3.1/act2/Relu_output_0, %onnx::Conv_244, %onnx::Conv_245), scope: timm.models.resnet.ResNet::/torch.nn.modules.container.Sequential::layer4/timm.models.resnet.BasicBlock::layer4.0/torch.nn.modules.container.Sequential::downsample/torch.nn.modules.conv.Conv2d::downsample.0 # /home/fatuus/deepschool-cvr-conversion/venv/lib/python3.8/site-packages/torch/nn/modules/conv.py:459:0\n",
      "  %/layer4/layer4.0/Add_output_0 : Float(*, 512, 8, 8, strides=[32768, 64, 8, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"/layer4/layer4.0/Add\"](%/layer4/layer4.0/conv2/Conv_output_0, %/layer4/layer4.0/downsample/downsample.0/Conv_output_0), scope: timm.models.resnet.ResNet::/torch.nn.modules.container.Sequential::layer4/timm.models.resnet.BasicBlock::layer4.0 # /home/fatuus/deepschool-cvr-conversion/venv/lib/python3.8/site-packages/timm/models/resnet.py:344:0\n",
      "  %/layer4/layer4.0/act2/Relu_output_0 : Float(*, 512, 8, 8, strides=[32768, 64, 8, 1], requires_grad=1, device=cpu) = onnx::Relu[onnx_name=\"/layer4/layer4.0/act2/Relu\"](%/layer4/layer4.0/Add_output_0), scope: timm.models.resnet.ResNet::/torch.nn.modules.container.Sequential::layer4/timm.models.resnet.BasicBlock::layer4.0/torch.nn.modules.activation.ReLU::act2 # /home/fatuus/deepschool-cvr-conversion/venv/lib/python3.8/site-packages/torch/nn/functional.py:1455:0\n",
      "  %/layer4/layer4.1/conv1/Conv_output_0 : Float(*, 512, 8, 8, strides=[32768, 64, 8, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name=\"/layer4/layer4.1/conv1/Conv\"](%/layer4/layer4.0/act2/Relu_output_0, %onnx::Conv_247, %onnx::Conv_248), scope: timm.models.resnet.ResNet::/torch.nn.modules.container.Sequential::layer4/timm.models.resnet.BasicBlock::layer4.1/torch.nn.modules.conv.Conv2d::conv1 # /home/fatuus/deepschool-cvr-conversion/venv/lib/python3.8/site-packages/torch/nn/modules/conv.py:459:0\n",
      "  %/layer4/layer4.1/act1/Relu_output_0 : Float(*, 512, 8, 8, strides=[32768, 64, 8, 1], requires_grad=1, device=cpu) = onnx::Relu[onnx_name=\"/layer4/layer4.1/act1/Relu\"](%/layer4/layer4.1/conv1/Conv_output_0), scope: timm.models.resnet.ResNet::/torch.nn.modules.container.Sequential::layer4/timm.models.resnet.BasicBlock::layer4.1/torch.nn.modules.activation.ReLU::act1 # /home/fatuus/deepschool-cvr-conversion/venv/lib/python3.8/site-packages/torch/nn/functional.py:1455:0\n",
      "  %/layer4/layer4.1/conv2/Conv_output_0 : Float(*, 512, 8, 8, strides=[32768, 64, 8, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name=\"/layer4/layer4.1/conv2/Conv\"](%/layer4/layer4.1/act1/Relu_output_0, %onnx::Conv_250, %onnx::Conv_251), scope: timm.models.resnet.ResNet::/torch.nn.modules.container.Sequential::layer4/timm.models.resnet.BasicBlock::layer4.1/torch.nn.modules.conv.Conv2d::conv2 # /home/fatuus/deepschool-cvr-conversion/venv/lib/python3.8/site-packages/torch/nn/modules/conv.py:459:0\n",
      "  %/layer4/layer4.1/Add_output_0 : Float(*, 512, 8, 8, strides=[32768, 64, 8, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"/layer4/layer4.1/Add\"](%/layer4/layer4.1/conv2/Conv_output_0, %/layer4/layer4.0/act2/Relu_output_0), scope: timm.models.resnet.ResNet::/torch.nn.modules.container.Sequential::layer4/timm.models.resnet.BasicBlock::layer4.1 # /home/fatuus/deepschool-cvr-conversion/venv/lib/python3.8/site-packages/timm/models/resnet.py:344:0\n",
      "  %/layer4/layer4.1/act2/Relu_output_0 : Float(*, 512, 8, 8, strides=[32768, 64, 8, 1], requires_grad=1, device=cpu) = onnx::Relu[onnx_name=\"/layer4/layer4.1/act2/Relu\"](%/layer4/layer4.1/Add_output_0), scope: timm.models.resnet.ResNet::/torch.nn.modules.container.Sequential::layer4/timm.models.resnet.BasicBlock::layer4.1/torch.nn.modules.activation.ReLU::act2 # /home/fatuus/deepschool-cvr-conversion/venv/lib/python3.8/site-packages/torch/nn/functional.py:1455:0\n",
      "  %/global_pool/pool/GlobalAveragePool_output_0 : Float(*, 512, 1, 1, strides=[512, 1, 1, 1], requires_grad=1, device=cpu) = onnx::GlobalAveragePool[onnx_name=\"/global_pool/pool/GlobalAveragePool\"](%/layer4/layer4.1/act2/Relu_output_0), scope: timm.models.resnet.ResNet::/timm.models.layers.adaptive_avgmax_pool.SelectAdaptivePool2d::global_pool/torch.nn.modules.pooling.AdaptiveAvgPool2d::pool # /home/fatuus/deepschool-cvr-conversion/venv/lib/python3.8/site-packages/torch/nn/functional.py:1214:0\n",
      "  %/global_pool/flatten/Flatten_output_0 : Float(*, 512, strides=[512, 1], requires_grad=1, device=cpu) = onnx::Flatten[axis=1, onnx_name=\"/global_pool/flatten/Flatten\"](%/global_pool/pool/GlobalAveragePool_output_0), scope: timm.models.resnet.ResNet::/timm.models.layers.adaptive_avgmax_pool.SelectAdaptivePool2d::global_pool/torch.nn.modules.flatten.Flatten::flatten # /home/fatuus/deepschool-cvr-conversion/venv/lib/python3.8/site-packages/torch/nn/modules/flatten.py:46:0\n",
      "  %output : Float(*, 17, strides=[17, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1, onnx_name=\"/fc/Gemm\"](%/global_pool/flatten/Flatten_output_0, %fc.weight, %fc.bias), scope: timm.models.resnet.ResNet::/timm.models.layers.linear.Linear::fc # /home/fatuus/deepschool-cvr-conversion/venv/lib/python3.8/site-packages/timm/models/layers/linear.py:19:0\n",
      "  return (%output)\n",
      "\n",
      "============= Diagnostic Run torch.onnx.export version 2.0.1+cu117 =============\n",
      "verbose: False, log level: Level.ERROR\n",
      "======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "th.onnx.export(\n",
    "    model_torch.model,\n",
    "    th.rand(1, 3, MAX_UINT8, MAX_UINT8).to(th.float32),\n",
    "    \"weights/model.onnx\",\n",
    "    verbose=True,\n",
    "    input_names=['input'],\n",
    "    output_names=['output'],\n",
    "    dynamic_axes = {\n",
    "        'input': [0], \n",
    "        'output': [0]\n",
    "    },\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "692d0ae5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>platform</th>\n",
       "      <th>batch_sz</th>\n",
       "      <th>tool</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.002859</td>\n",
       "      <td>1GPU</td>\n",
       "      <td>1</td>\n",
       "      <td>ONNX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.002777</td>\n",
       "      <td>1GPU</td>\n",
       "      <td>2</td>\n",
       "      <td>ONNX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.004151</td>\n",
       "      <td>1GPU</td>\n",
       "      <td>4</td>\n",
       "      <td>ONNX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.007069</td>\n",
       "      <td>1GPU</td>\n",
       "      <td>8</td>\n",
       "      <td>ONNX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.011151</td>\n",
       "      <td>1GPU</td>\n",
       "      <td>16</td>\n",
       "      <td>ONNX</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       time platform  batch_sz  tool\n",
       "0  0.002859     1GPU         1  ONNX\n",
       "1  0.002777     1GPU         2  ONNX\n",
       "2  0.004151     1GPU         4  ONNX\n",
       "3  0.007069     1GPU         8  ONNX\n",
       "4  0.011151     1GPU        16  ONNX"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"./config/onnx_gpu.yaml\") as fp:\n",
    "    cfg_onnx = yaml.safe_load(fp)\n",
    "cfg_onnx[\"device\"] = DEVICE\n",
    "model_onnx = ModelONNX(cfg_onnx)\n",
    "records = []\n",
    "for batch_sz in BATCH_SIZES:\n",
    "    avg, _ = benchmark(\n",
    "        model=model_onnx,\n",
    "        input_shape=(batch_sz, 3, MAX_UINT8, MAX_UINT8),\n",
    "        nwarmup=WARMUP,\n",
    "        nruns=N_RUNS,\n",
    "        print_step=N_PRINT,\n",
    "        verbose=VERBOSE\n",
    "    )\n",
    "    records.append(\n",
    "        {\n",
    "            \"time\": avg,\n",
    "            \"platform\": PLATFORM, \n",
    "            \"batch_sz\": batch_sz,\n",
    "            \"tool\": \"ONNX\"\n",
    "        }\n",
    "    )\n",
    "inference_records.extend(records)\n",
    "pd.DataFrame(records)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8132d86a",
   "metadata": {},
   "source": [
    "### OpenVino Model\n",
    "bash command to convert ONNX -> OpenVino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "16f2f502",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check for a new version of Intel(R) Distribution of OpenVINO(TM) toolkit here https://software.intel.com/content/www/us/en/develop/tools/openvino-toolkit/download.html?cid=other&source=prod&campid=ww_2023_bu_IOTG_OpenVINO-2022-3&content=upg_all&medium=organic or on https://github.com/openvinotoolkit/openvino\n",
      "[ INFO ] The model was converted to IR v11, the latest model format that corresponds to the source DL framework input/output format. While IR v11 is backwards compatible with OpenVINO Inference Engine API v1.0, please use API v2.0 (as of 2022.1) to take advantage of the latest improvements in IR v11.\n",
      "Find more information about API v2.0 and IR v11 at https://docs.openvino.ai/latest/openvino_2_0_transition_guide.html\n",
      "[ SUCCESS ] Generated IR version 11 model.\n",
      "[ SUCCESS ] XML file: /home/fatuus/deepschool-cvr-conversion/weights/openvino/model.xml\n",
      "[ SUCCESS ] BIN file: /home/fatuus/deepschool-cvr-conversion/weights/openvino/model.bin\n"
     ]
    }
   ],
   "source": [
    "\n",
    "! mo --input_model weights/model.onnx --output_dir weights/openvino\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fc89ee47",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.model.openvino import ModelOpenVino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d83ba716",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>platform</th>\n",
       "      <th>batch_sz</th>\n",
       "      <th>tool</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.052132</td>\n",
       "      <td>1GPU</td>\n",
       "      <td>1</td>\n",
       "      <td>OpenVino</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.089428</td>\n",
       "      <td>1GPU</td>\n",
       "      <td>2</td>\n",
       "      <td>OpenVino</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.178273</td>\n",
       "      <td>1GPU</td>\n",
       "      <td>4</td>\n",
       "      <td>OpenVino</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.351515</td>\n",
       "      <td>1GPU</td>\n",
       "      <td>8</td>\n",
       "      <td>OpenVino</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.699047</td>\n",
       "      <td>1GPU</td>\n",
       "      <td>16</td>\n",
       "      <td>OpenVino</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       time platform  batch_sz      tool\n",
       "0  0.052132     1GPU         1  OpenVino\n",
       "1  0.089428     1GPU         2  OpenVino\n",
       "2  0.178273     1GPU         4  OpenVino\n",
       "3  0.351515     1GPU         8  OpenVino\n",
       "4  0.699047     1GPU        16  OpenVino"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"./config/openvino.yaml\") as fp:\n",
    "    cfg_ov = yaml.safe_load(fp)\n",
    "cfg_ov[\"device\"] = DEVICE\n",
    "\n",
    "model_ov = ModelOpenVino(cfg_ov)\n",
    "records = []\n",
    "for batch_sz in BATCH_SIZES:\n",
    "    avg, _ = benchmark(\n",
    "        model=model_ov,\n",
    "        input_shape=(batch_sz, 3, MAX_UINT8, MAX_UINT8),\n",
    "        nwarmup=WARMUP,\n",
    "        nruns=N_RUNS,\n",
    "        print_step=N_PRINT,\n",
    "        verbose=VERBOSE\n",
    "    )\n",
    "    records.append(\n",
    "        {\n",
    "            \"time\": avg,\n",
    "            \"platform\": PLATFORM, \n",
    "            \"batch_sz\": batch_sz,\n",
    "            \"tool\": \"OpenVino\"\n",
    "        }\n",
    "    )\n",
    "inference_records.extend(records)\n",
    "pd.DataFrame(records)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dcae0f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\n",
    "    \"results/inference_results_1gpu.json\", \n",
    "    \"w\",\n",
    "    encoding=\"utf8\"\n",
    ") as fp:\n",
    "    json.dump(fp=fp, obj=inference_records)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8924d96b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
