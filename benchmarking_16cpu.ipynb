{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1e9fd015",
   "metadata": {},
   "source": [
    "# Benchmark of inference tools on 8CPU\n",
    "\n",
    "Comparisson of different tools for model inference on 8 CPU.\n",
    "\n",
    "|                     |                                         |\n",
    "|---------------------|-------------------------------------------|\n",
    "|**Hard ware**         | Intel Ice Lake with NVIDIA® Tesla® T4 with 4 CPUs and 16 Gb RAM.  |\n",
    "|**Software Platform**| host |\n",
    "|**Tools to compare**| Torch Script, Torch Trace, ONNX, Open Vino|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4a0ccb9",
   "metadata": {},
   "source": [
    "### Common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ba280ca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6faf9134",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import timm\n",
    "import torch as th\n",
    "import typing as tp\n",
    "import numpy as np\n",
    "import cv2\n",
    "import yaml\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "from src.utils import get_batch, MAX_UINT8, benchmark\n",
    "\n",
    "\n",
    "DATA_DIR = \"./images\"\n",
    "BATCH_SIZES = [1,2,4,8,16]\n",
    "PLATFORM = \"16cpu\"\n",
    "WARMUP = 5\n",
    "N_RUNS = 10\n",
    "VERBOSE = False\n",
    "N_PRINT = 5\n",
    "DEVICE = \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f527b9c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# batches = dict()\n",
    "# for batch_sz in BATCH_SIZES:\n",
    "#     batch = get_batch(DATA_DIR, batch_sz)\n",
    "#     batches[batch_sz] = batch\n",
    "#     del batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faac48b5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "inference_records = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1895b3fb",
   "metadata": {},
   "source": [
    "### Torch Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81e19404",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from src.model.torch import ModelTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d8c3580",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "records = []\n",
    "with open(\"./config/torch.yaml\") as fp:\n",
    "    cfg_torch = yaml.safe_load(fp)\n",
    "\n",
    "cfg_torch[\"device\"] = DEVICE\n",
    "model_torch = ModelTorch(cfg_torch)\n",
    "for batch_sz in BATCH_SIZES:\n",
    "    avg, stdev = benchmark(\n",
    "        model=model_torch,\n",
    "        input_shape=(batch_sz, 3, MAX_UINT8, MAX_UINT8),\n",
    "        nwarmup=WARMUP,\n",
    "        nruns=N_RUNS,\n",
    "        print_step=N_PRINT,\n",
    "        verbose=VERBOSE\n",
    "    )\n",
    "    records.append(\n",
    "        {\n",
    "            \"time\": avg,\n",
    "            \"platform\": PLATFORM, \n",
    "            \"batch_sz\": batch_sz,\n",
    "            \"tool\": \"Torch\"\n",
    "        }\n",
    "    )\n",
    "inference_records.extend(records)\n",
    "pd.DataFrame(records)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea16eed9",
   "metadata": {},
   "source": [
    "### TorchScript Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e231b9e0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from src.model.torch_jit import ModelTorchJIT\n",
    "\n",
    "tmp = th.jit.script(model_torch.model)\n",
    "th.jit.save(tmp, \"weights/model_scripted.th\")\n",
    "\n",
    "with open(\"./config/torch_scripted.yaml\") as fp:\n",
    "    cfg_scripted = yaml.safe_load(fp)\n",
    "cfg_scripted[\"device\"] = DEVICE\n",
    "model_scripted = ModelTorchJIT(cfg_scripted)\n",
    "records = []\n",
    "for batch_sz in BATCH_SIZES:\n",
    "    avg, stdev = benchmark(\n",
    "        model=model_scripted,\n",
    "        input_shape=(batch_sz, 3, MAX_UINT8, MAX_UINT8),\n",
    "        nwarmup=WARMUP,\n",
    "        nruns=N_RUNS,\n",
    "        print_step=N_PRINT,\n",
    "        verbose=VERBOSE\n",
    "    )\n",
    "    records.append(\n",
    "        {\n",
    "            \"time\": avg,\n",
    "            \"platform\": PLATFORM, \n",
    "            \"batch_sz\": batch_sz,\n",
    "            \"tool\": \"TorchScript\"\n",
    "        }\n",
    "    )\n",
    "inference_records.extend(records)\n",
    "pd.DataFrame(records)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "634774d5",
   "metadata": {},
   "source": [
    "### TorchTrace Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6563604",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from src.model.torch_jit import ModelTorchJIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "099a8c7e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tmp = th.jit.trace(\n",
    "    model_torch.model,\n",
    "    th.rand(1, 3, MAX_UINT8, MAX_UINT8).to(th.float32)\n",
    ")\n",
    "th.jit.save(tmp, \"weights/model_traced.th\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f5d5212",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(\"./config/torch_traced.yaml\") as fp:\n",
    "    cfg_traced = yaml.safe_load(fp)\n",
    "cfg_traced[\"device\"] = DEVICE\n",
    "model_traced = ModelTorchJIT(cfg_traced)\n",
    "records = []\n",
    "for batch_sz in BATCH_SIZES:\n",
    "    avg, _=benchmark(\n",
    "        model=model_traced,\n",
    "        input_shape=(batch_sz, 3, MAX_UINT8, MAX_UINT8),\n",
    "        nwarmup=WARMUP,\n",
    "        nruns=N_RUNS,\n",
    "        print_step=N_PRINT,\n",
    "        verbose=VERBOSE\n",
    "    )\n",
    "    records.append(\n",
    "        {\n",
    "            \"time\": avg,\n",
    "            \"platform\": PLATFORM, \n",
    "            \"batch_sz\": batch_sz,\n",
    "            \"tool\": \"TorchTrace\"\n",
    "        }\n",
    "    )\n",
    "inference_records.extend(records)\n",
    "pd.DataFrame(records)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d38aa10f",
   "metadata": {},
   "source": [
    "### ONNX Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffdc3168",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from src.model.onnx import ModelONNX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0584f686",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "th.onnx.export(\n",
    "    model_torch.model,\n",
    "    th.rand(1, 3, MAX_UINT8, MAX_UINT8).to(th.float32),\n",
    "    \"weights/model.onnx\",\n",
    "    verbose=True,\n",
    "    input_names=['input'],\n",
    "    output_names=['output'],\n",
    "    dynamic_axes = {\n",
    "        'input': [0], \n",
    "        'output': [0]\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9839c1e3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(\"./config/onnx_cpu.yaml\") as fp:\n",
    "    cfg_onnx = yaml.safe_load(fp)\n",
    "cfg_onnx[\"device\"] = DEVICE\n",
    "model_onnx = ModelONNX(cfg_onnx)\n",
    "records = []\n",
    "for batch_sz in BATCH_SIZES:\n",
    "    avg, _ = benchmark(\n",
    "        model=model_onnx,\n",
    "        input_shape=(batch_sz, 3, MAX_UINT8, MAX_UINT8),\n",
    "        nwarmup=WARMUP,\n",
    "        nruns=N_RUNS,\n",
    "        print_step=N_PRINT,\n",
    "        verbose=VERBOSE\n",
    "    )\n",
    "    records.append(\n",
    "        {\n",
    "            \"time\": avg,\n",
    "            \"platform\": PLATFORM, \n",
    "            \"batch_sz\": batch_sz,\n",
    "            \"tool\": \"ONNX\"\n",
    "        }\n",
    "    )\n",
    "inference_records.extend(records)\n",
    "pd.DataFrame(records)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cac70a3d",
   "metadata": {},
   "source": [
    "### OpenVino Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ecedcc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# bash command to convert ONNX -> OpenVino\n",
    "!mo --input_model weights/model.onnx --output_dir weights/openvino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ef91083",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from src.model.openvino import ModelOpenVino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c3dd85e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(\"./config/openvino.yaml\") as fp:\n",
    "    cfg_ov = yaml.safe_load(fp)\n",
    "cfg_ov[\"device\"] = DEVICE\n",
    "\n",
    "model_ov = ModelOpenVino(cfg_ov)\n",
    "records = []\n",
    "for batch_sz in BATCH_SIZES:\n",
    "    avg, _ = benchmark(\n",
    "        model=model_ov,\n",
    "        input_shape=(batch_sz, 3, MAX_UINT8, MAX_UINT8),\n",
    "        nwarmup=WARMUP,\n",
    "        nruns=N_RUNS,\n",
    "        print_step=N_PRINT,\n",
    "        verbose=VERBOSE\n",
    "    )\n",
    "    records.append(\n",
    "        {\n",
    "            \"time\": avg,\n",
    "            \"platform\": PLATFORM, \n",
    "            \"batch_sz\": batch_sz,\n",
    "            \"tool\": \"OpenVino\"\n",
    "        }\n",
    "    )\n",
    "inference_records.extend(records)\n",
    "pd.DataFrame(records)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f328563",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(\n",
    "    \"results/inference_results_16cpu.json\", \n",
    "    \"w\",\n",
    "    encoding=\"utf8\"\n",
    ") as fp:\n",
    "    json.dump(fp=fp, obj=inference_records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7238f4d8-cfc5-4b25-8f41-da82029a9dbd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(inference_records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d356b32-ebd4-44ad-bece-559c9e9842f6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
