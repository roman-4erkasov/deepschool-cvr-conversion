{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "44747e9c",
   "metadata": {},
   "source": [
    "# Benchmark of inference tools on GPU\n",
    "\n",
    "Comparisson of different tools for model inference on GPU.\n",
    "\n",
    "|                     |                                         |\n",
    "|---------------------|-------------------------------------------|\n",
    "|**Hard ware**         | Intel Ice Lake with NVIDIA® Tesla® T4 with 4 CPUs and 16 Gb RAM.  |\n",
    "|**Software Platform**| host |\n",
    "|**Tools to compare**| Torch Script, Torch Trace, ONNX, Open Vino|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44238f66",
   "metadata": {},
   "source": [
    "### Common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "77c29c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "353e8880",
   "metadata": {},
   "outputs": [],
   "source": [
    "import timm\n",
    "import torch as th\n",
    "import typing as tp\n",
    "import numpy as np\n",
    "import cv2\n",
    "import yaml\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "from src.utils import get_batch, MAX_UINT8, benchmark\n",
    "\n",
    "\n",
    "DATA_DIR = \"./images\"\n",
    "BATCH_SIZES = [1,2,4,8,16]\n",
    "PLATFORM = \"1GPU\"\n",
    "WARMUP = 5\n",
    "N_RUNS = 10\n",
    "VERBOSE = False\n",
    "N_PRINT = 5\n",
    "DEVICE = \"cuda\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b431cf63",
   "metadata": {},
   "outputs": [],
   "source": [
    "batches = dict()\n",
    "for batch_sz in BATCH_SIZES:\n",
    "    batch = get_batch(DATA_DIR, batch_sz)\n",
    "    batches[batch_sz] = batch\n",
    "    del batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "245744dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_records = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3a6f16a",
   "metadata": {},
   "source": [
    "### Torch Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b7f23763",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.model.torch import ModelTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "92efe23b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warm up ...\n",
      "Start timing ...\n",
      "Iteration 10/20, avg batch time 40.72 ± 0.34 ms.\n",
      "Iteration 20/20, avg batch time 40.96 ± 0.39 ms.\n",
      "Input shape: (1, 3, 255, 255)\n",
      "Output features size: (17,)\n",
      "Average throughput: 24.413 images/second\n",
      "Warm up ...\n",
      "Start timing ...\n",
      "Iteration 10/20, avg batch time 67.94 ± 1.47 ms.\n",
      "Iteration 20/20, avg batch time 67.86 ± 1.13 ms.\n",
      "Input shape: (2, 3, 255, 255)\n",
      "Output features size: (2, 17)\n",
      "Average throughput: 29.472 images/second\n",
      "Warm up ...\n",
      "Start timing ...\n",
      "Iteration 10/20, avg batch time 128.25 ± 0.70 ms.\n",
      "Iteration 20/20, avg batch time 128.64 ± 1.57 ms.\n",
      "Input shape: (4, 3, 255, 255)\n",
      "Output features size: (4, 17)\n",
      "Average throughput: 31.094 images/second\n",
      "Warm up ...\n",
      "Start timing ...\n",
      "Iteration 10/20, avg batch time 267.29 ± 2.03 ms.\n",
      "Iteration 20/20, avg batch time 267.72 ± 1.60 ms.\n",
      "Input shape: (8, 3, 255, 255)\n",
      "Output features size: (8, 17)\n",
      "Average throughput: 29.882 images/second\n",
      "Warm up ...\n",
      "Start timing ...\n",
      "Iteration 10/20, avg batch time 559.57 ± 10.73 ms.\n",
      "Iteration 20/20, avg batch time 557.19 ± 10.88 ms.\n",
      "Input shape: (16, 3, 255, 255)\n",
      "Output features size: (16, 17)\n",
      "Average throughput: 28.715 images/second\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>platform</th>\n",
       "      <th>batch_sz</th>\n",
       "      <th>tool</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.040963</td>\n",
       "      <td>1GPU</td>\n",
       "      <td>1</td>\n",
       "      <td>Torch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.067860</td>\n",
       "      <td>1GPU</td>\n",
       "      <td>2</td>\n",
       "      <td>Torch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.128642</td>\n",
       "      <td>1GPU</td>\n",
       "      <td>4</td>\n",
       "      <td>Torch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.267724</td>\n",
       "      <td>1GPU</td>\n",
       "      <td>8</td>\n",
       "      <td>Torch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.557194</td>\n",
       "      <td>1GPU</td>\n",
       "      <td>16</td>\n",
       "      <td>Torch</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       time platform  batch_sz   tool\n",
       "0  0.040963     1GPU         1  Torch\n",
       "1  0.067860     1GPU         2  Torch\n",
       "2  0.128642     1GPU         4  Torch\n",
       "3  0.267724     1GPU         8  Torch\n",
       "4  0.557194     1GPU        16  Torch"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "records = []\n",
    "with open(\"./config/torch.yaml\") as fp:\n",
    "    cfg_torch = yaml.safe_load(fp)\n",
    "\n",
    "cfg_torch[\"device\"] = DEVICE\n",
    "model_torch = ModelTorch(cfg_torch)\n",
    "for batch_sz in BATCH_SIZES:\n",
    "    avg, stdev = benchmark(\n",
    "        model=model_torch,\n",
    "        input_shape=(batch_sz, 3, MAX_UINT8, MAX_UINT8),\n",
    "        nwarmup=WARMUP,\n",
    "        nruns=N_RUNS,\n",
    "        print_step=N_PRINT,\n",
    "        verbose=VERBOSE\n",
    "    )\n",
    "    records.append(\n",
    "        {\n",
    "            \"time\": avg,\n",
    "            \"platform\": PLATFORM, \n",
    "            \"batch_sz\": batch_sz,\n",
    "            \"tool\": \"Torch\"\n",
    "        }\n",
    "    )\n",
    "inference_records.extend(records)\n",
    "pd.DataFrame(records)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31bce913",
   "metadata": {},
   "source": [
    "### TorchScript Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0e3ccb1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1533: UserWarning: operator() profile_node %833 : bool = prim::profile_ivalue(%training.1)\n",
      " does not have profile information (Triggered internally at /opt/pytorch/pytorch/third_party/nvfuser/csrc/graph_fuser.cpp:104.)\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>platform</th>\n",
       "      <th>batch_sz</th>\n",
       "      <th>tool</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.004041</td>\n",
       "      <td>1GPU</td>\n",
       "      <td>1</td>\n",
       "      <td>TorchScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.005542</td>\n",
       "      <td>1GPU</td>\n",
       "      <td>2</td>\n",
       "      <td>TorchScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.007792</td>\n",
       "      <td>1GPU</td>\n",
       "      <td>4</td>\n",
       "      <td>TorchScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.009527</td>\n",
       "      <td>1GPU</td>\n",
       "      <td>8</td>\n",
       "      <td>TorchScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.015114</td>\n",
       "      <td>1GPU</td>\n",
       "      <td>16</td>\n",
       "      <td>TorchScript</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       time platform  batch_sz         tool\n",
       "0  0.004041     1GPU         1  TorchScript\n",
       "1  0.005542     1GPU         2  TorchScript\n",
       "2  0.007792     1GPU         4  TorchScript\n",
       "3  0.009527     1GPU         8  TorchScript\n",
       "4  0.015114     1GPU        16  TorchScript"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.model.torch_jit import ModelTorchJIT\n",
    "\n",
    "tmp = th.jit.script(model_torch.model)\n",
    "th.jit.save(tmp, \"weights/model_scripted.th\")\n",
    "\n",
    "with open(\"./config/torch_scripted.yaml\") as fp:\n",
    "    cfg_scripted = yaml.safe_load(fp)\n",
    "cfg_scripted[\"device\"] = \"cuda\"\n",
    "model_scripted = ModelTorchJIT(cfg_scripted)\n",
    "records = []\n",
    "for batch_sz in BATCH_SIZES:\n",
    "    avg, stdev = benchmark(\n",
    "        model=model_scripted,\n",
    "        input_shape=(batch_sz, 3, MAX_UINT8, MAX_UINT8),\n",
    "        nwarmup=WARMUP,\n",
    "        nruns=N_RUNS,\n",
    "        print_step=N_PRINT,\n",
    "        verbose=VERBOSE\n",
    "    )\n",
    "    records.append(\n",
    "        {\n",
    "            \"time\": avg,\n",
    "            \"platform\": PLATFORM, \n",
    "            \"batch_sz\": batch_sz,\n",
    "            \"tool\": \"TorchScript\"\n",
    "        }\n",
    "    )\n",
    "inference_records.extend(records)\n",
    "pd.DataFrame(records)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "440bede6",
   "metadata": {},
   "source": [
    "### TorchTrace Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23bc44ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.model.torch_jit import ModelTorchJIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fec47a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = th.jit.trace(\n",
    "    model_torch.model,\n",
    "    th.rand(1, 3, MAX_UINT8, MAX_UINT8).to(th.float32)\n",
    ")\n",
    "th.jit.save(tmp, \"weights/model_traced.th\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "66143c9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warm up ...\n",
      "Start timing ...\n",
      "Iteration 5/10, avg batch time 3.99 ± 0.01 ms.\n",
      "Iteration 10/10, avg batch time 4.01 ± 0.02 ms.\n",
      "Input shape: (1, 3, 255, 255)\n",
      "Output features size: (17,)\n",
      "Average throughput: 249.401 images/second\n",
      "Warm up ...\n",
      "Start timing ...\n",
      "Iteration 5/10, avg batch time 3.99 ± 0.01 ms.\n",
      "Iteration 10/10, avg batch time 4.00 ± 0.01 ms.\n",
      "Input shape: (1, 3, 255, 255)\n",
      "Output features size: (17,)\n",
      "Average throughput: 250.245 images/second\n",
      "Warm up ...\n",
      "Start timing ...\n",
      "Iteration 5/10, avg batch time 4.00 ± 0.01 ms.\n",
      "Iteration 10/10, avg batch time 4.00 ± 0.01 ms.\n",
      "Input shape: (1, 3, 255, 255)\n",
      "Output features size: (17,)\n",
      "Average throughput: 249.701 images/second\n",
      "Warm up ...\n",
      "Start timing ...\n",
      "Iteration 5/10, avg batch time 2.74 ± 0.01 ms.\n",
      "Iteration 10/10, avg batch time 2.73 ± 0.01 ms.\n",
      "Input shape: (1, 3, 255, 255)\n",
      "Output features size: (17,)\n",
      "Average throughput: 365.654 images/second\n",
      "Warm up ...\n",
      "Start timing ...\n",
      "Iteration 5/10, avg batch time 2.73 ± 0.01 ms.\n",
      "Iteration 10/10, avg batch time 2.72 ± 0.02 ms.\n",
      "Input shape: (1, 3, 255, 255)\n",
      "Output features size: (17,)\n",
      "Average throughput: 368.054 images/second\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>platform</th>\n",
       "      <th>batch_sz</th>\n",
       "      <th>tool</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.004010</td>\n",
       "      <td>1GPU</td>\n",
       "      <td>1</td>\n",
       "      <td>TorchTrace</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.003996</td>\n",
       "      <td>1GPU</td>\n",
       "      <td>2</td>\n",
       "      <td>TorchTrace</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.004005</td>\n",
       "      <td>1GPU</td>\n",
       "      <td>4</td>\n",
       "      <td>TorchTrace</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.002735</td>\n",
       "      <td>1GPU</td>\n",
       "      <td>8</td>\n",
       "      <td>TorchTrace</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.002717</td>\n",
       "      <td>1GPU</td>\n",
       "      <td>16</td>\n",
       "      <td>TorchTrace</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       time platform  batch_sz        tool\n",
       "0  0.004010     1GPU         1  TorchTrace\n",
       "1  0.003996     1GPU         2  TorchTrace\n",
       "2  0.004005     1GPU         4  TorchTrace\n",
       "3  0.002735     1GPU         8  TorchTrace\n",
       "4  0.002717     1GPU        16  TorchTrace"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"./config/torch_traced.yaml\") as fp:\n",
    "    cfg_traced = yaml.safe_load(fp)\n",
    "cfg_traced[\"device\"] = DEVICE\n",
    "model_traced = ModelTorchJIT(cfg_traced)\n",
    "records = []\n",
    "for batch_sz in BATCH_SIZES:\n",
    "    avg, _=benchmark(\n",
    "        model=model_traced,\n",
    "        input_shape=(batch_sz, 3, MAX_UINT8, MAX_UINT8),\n",
    "        nwarmup=WARMUP,\n",
    "        nruns=N_RUNS,\n",
    "        print_step=N_PRINT,\n",
    "        verbose=VERBOSE\n",
    "    )\n",
    "    records.append(\n",
    "        {\n",
    "            \"time\": avg,\n",
    "            \"platform\": PLATFORM, \n",
    "            \"batch_sz\": batch_sz,\n",
    "            \"tool\": \"TorchTrace\"\n",
    "        }\n",
    "    )\n",
    "inference_records.extend(records)\n",
    "pd.DataFrame(records)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "410dbb9e",
   "metadata": {},
   "source": [
    "### ONNX Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "794ecac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.model.onnx import ModelONNX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ebaeb44c",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/torch/onnx/utils.py:2052: UserWarning: No names were found for specified dynamic axes of provided input.Automatically generated names will be applied to each dynamic axes of input input\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/torch/onnx/utils.py:2052: UserWarning: No names were found for specified dynamic axes of provided input.Automatically generated names will be applied to each dynamic axes of input output\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exported graph: graph(%input : Float(*, 3, 255, 255, strides=[195075, 65025, 255, 1], requires_grad=0, device=cpu),\n",
      "      %fc.weight : Float(17, 512, strides=[512, 1], requires_grad=1, device=cpu),\n",
      "      %fc.bias : Float(17, strides=[1], requires_grad=1, device=cpu),\n",
      "      %onnx::Conv_193 : Float(64, 3, 7, 7, strides=[147, 49, 7, 1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_194 : Float(64, strides=[1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_196 : Float(64, 64, 3, 3, strides=[576, 9, 3, 1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_197 : Float(64, strides=[1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_199 : Float(64, 64, 3, 3, strides=[576, 9, 3, 1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_200 : Float(64, strides=[1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_202 : Float(64, 64, 3, 3, strides=[576, 9, 3, 1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_203 : Float(64, strides=[1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_205 : Float(64, 64, 3, 3, strides=[576, 9, 3, 1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_206 : Float(64, strides=[1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_208 : Float(128, 64, 3, 3, strides=[576, 9, 3, 1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_209 : Float(128, strides=[1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_211 : Float(128, 128, 3, 3, strides=[1152, 9, 3, 1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_212 : Float(128, strides=[1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_214 : Float(128, 64, 1, 1, strides=[64, 1, 1, 1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_215 : Float(128, strides=[1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_217 : Float(128, 128, 3, 3, strides=[1152, 9, 3, 1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_218 : Float(128, strides=[1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_220 : Float(128, 128, 3, 3, strides=[1152, 9, 3, 1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_221 : Float(128, strides=[1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_223 : Float(256, 128, 3, 3, strides=[1152, 9, 3, 1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_224 : Float(256, strides=[1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_226 : Float(256, 256, 3, 3, strides=[2304, 9, 3, 1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_227 : Float(256, strides=[1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_229 : Float(256, 128, 1, 1, strides=[128, 1, 1, 1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_230 : Float(256, strides=[1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_232 : Float(256, 256, 3, 3, strides=[2304, 9, 3, 1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_233 : Float(256, strides=[1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_235 : Float(256, 256, 3, 3, strides=[2304, 9, 3, 1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_236 : Float(256, strides=[1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_238 : Float(512, 256, 3, 3, strides=[2304, 9, 3, 1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_239 : Float(512, strides=[1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_241 : Float(512, 512, 3, 3, strides=[4608, 9, 3, 1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_242 : Float(512, strides=[1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_244 : Float(512, 256, 1, 1, strides=[256, 1, 1, 1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_245 : Float(512, strides=[1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_247 : Float(512, 512, 3, 3, strides=[4608, 9, 3, 1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_248 : Float(512, strides=[1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_250 : Float(512, 512, 3, 3, strides=[4608, 9, 3, 1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_251 : Float(512, strides=[1], requires_grad=0, device=cpu)):\n",
      "  %/conv1/Conv_output_0 : Float(*, 64, 128, 128, strides=[1048576, 16384, 128, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[7, 7], pads=[3, 3, 3, 3], strides=[2, 2], onnx_name=\"/conv1/Conv\"](%input, %onnx::Conv_193, %onnx::Conv_194), scope: timm.models.resnet.ResNet::/torch.nn.modules.conv.Conv2d::conv1 # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:459:0\n",
      "  %/act1/Relu_output_0 : Float(*, 64, 128, 128, strides=[1048576, 16384, 128, 1], requires_grad=1, device=cpu) = onnx::Relu[onnx_name=\"/act1/Relu\"](%/conv1/Conv_output_0), scope: timm.models.resnet.ResNet::/torch.nn.modules.activation.ReLU::act1 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1455:0\n",
      "  %/maxpool/MaxPool_output_0 : Float(*, 64, 64, 64, strides=[262144, 4096, 64, 1], requires_grad=1, device=cpu) = onnx::MaxPool[ceil_mode=0, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[2, 2], onnx_name=\"/maxpool/MaxPool\"](%/act1/Relu_output_0), scope: timm.models.resnet.ResNet::/torch.nn.modules.pooling.MaxPool2d::maxpool # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:782:0\n",
      "  %/layer1/layer1.0/conv1/Conv_output_0 : Float(*, 64, 64, 64, strides=[262144, 4096, 64, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name=\"/layer1/layer1.0/conv1/Conv\"](%/maxpool/MaxPool_output_0, %onnx::Conv_196, %onnx::Conv_197), scope: timm.models.resnet.ResNet::/torch.nn.modules.container.Sequential::layer1/timm.models.resnet.BasicBlock::layer1.0/torch.nn.modules.conv.Conv2d::conv1 # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:459:0\n",
      "  %/layer1/layer1.0/act1/Relu_output_0 : Float(*, 64, 64, 64, strides=[262144, 4096, 64, 1], requires_grad=1, device=cpu) = onnx::Relu[onnx_name=\"/layer1/layer1.0/act1/Relu\"](%/layer1/layer1.0/conv1/Conv_output_0), scope: timm.models.resnet.ResNet::/torch.nn.modules.container.Sequential::layer1/timm.models.resnet.BasicBlock::layer1.0/torch.nn.modules.activation.ReLU::act1 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1455:0\n",
      "  %/layer1/layer1.0/conv2/Conv_output_0 : Float(*, 64, 64, 64, strides=[262144, 4096, 64, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name=\"/layer1/layer1.0/conv2/Conv\"](%/layer1/layer1.0/act1/Relu_output_0, %onnx::Conv_199, %onnx::Conv_200), scope: timm.models.resnet.ResNet::/torch.nn.modules.container.Sequential::layer1/timm.models.resnet.BasicBlock::layer1.0/torch.nn.modules.conv.Conv2d::conv2 # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:459:0\n",
      "  %/layer1/layer1.0/Add_output_0 : Float(*, 64, 64, 64, strides=[262144, 4096, 64, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"/layer1/layer1.0/Add\"](%/layer1/layer1.0/conv2/Conv_output_0, %/maxpool/MaxPool_output_0), scope: timm.models.resnet.ResNet::/torch.nn.modules.container.Sequential::layer1/timm.models.resnet.BasicBlock::layer1.0 # /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:115:0\n",
      "  %/layer1/layer1.0/act2/Relu_output_0 : Float(*, 64, 64, 64, strides=[262144, 4096, 64, 1], requires_grad=1, device=cpu) = onnx::Relu[onnx_name=\"/layer1/layer1.0/act2/Relu\"](%/layer1/layer1.0/Add_output_0), scope: timm.models.resnet.ResNet::/torch.nn.modules.container.Sequential::layer1/timm.models.resnet.BasicBlock::layer1.0/torch.nn.modules.activation.ReLU::act2 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1455:0\n",
      "  %/layer1/layer1.1/conv1/Conv_output_0 : Float(*, 64, 64, 64, strides=[262144, 4096, 64, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name=\"/layer1/layer1.1/conv1/Conv\"](%/layer1/layer1.0/act2/Relu_output_0, %onnx::Conv_202, %onnx::Conv_203), scope: timm.models.resnet.ResNet::/torch.nn.modules.container.Sequential::layer1/timm.models.resnet.BasicBlock::layer1.1/torch.nn.modules.conv.Conv2d::conv1 # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:459:0\n",
      "  %/layer1/layer1.1/act1/Relu_output_0 : Float(*, 64, 64, 64, strides=[262144, 4096, 64, 1], requires_grad=1, device=cpu) = onnx::Relu[onnx_name=\"/layer1/layer1.1/act1/Relu\"](%/layer1/layer1.1/conv1/Conv_output_0), scope: timm.models.resnet.ResNet::/torch.nn.modules.container.Sequential::layer1/timm.models.resnet.BasicBlock::layer1.1/torch.nn.modules.activation.ReLU::act1 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1455:0\n",
      "  %/layer1/layer1.1/conv2/Conv_output_0 : Float(*, 64, 64, 64, strides=[262144, 4096, 64, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name=\"/layer1/layer1.1/conv2/Conv\"](%/layer1/layer1.1/act1/Relu_output_0, %onnx::Conv_205, %onnx::Conv_206), scope: timm.models.resnet.ResNet::/torch.nn.modules.container.Sequential::layer1/timm.models.resnet.BasicBlock::layer1.1/torch.nn.modules.conv.Conv2d::conv2 # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:459:0\n",
      "  %/layer1/layer1.1/Add_output_0 : Float(*, 64, 64, 64, strides=[262144, 4096, 64, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"/layer1/layer1.1/Add\"](%/layer1/layer1.1/conv2/Conv_output_0, %/layer1/layer1.0/act2/Relu_output_0), scope: timm.models.resnet.ResNet::/torch.nn.modules.container.Sequential::layer1/timm.models.resnet.BasicBlock::layer1.1 # /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:115:0\n",
      "  %/layer1/layer1.1/act2/Relu_output_0 : Float(*, 64, 64, 64, strides=[262144, 4096, 64, 1], requires_grad=1, device=cpu) = onnx::Relu[onnx_name=\"/layer1/layer1.1/act2/Relu\"](%/layer1/layer1.1/Add_output_0), scope: timm.models.resnet.ResNet::/torch.nn.modules.container.Sequential::layer1/timm.models.resnet.BasicBlock::layer1.1/torch.nn.modules.activation.ReLU::act2 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1455:0\n",
      "  %/layer2/layer2.0/conv1/Conv_output_0 : Float(*, 128, 32, 32, strides=[131072, 1024, 32, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[2, 2], onnx_name=\"/layer2/layer2.0/conv1/Conv\"](%/layer1/layer1.1/act2/Relu_output_0, %onnx::Conv_208, %onnx::Conv_209), scope: timm.models.resnet.ResNet::/torch.nn.modules.container.Sequential::layer2/timm.models.resnet.BasicBlock::layer2.0/torch.nn.modules.conv.Conv2d::conv1 # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:459:0\n",
      "  %/layer2/layer2.0/act1/Relu_output_0 : Float(*, 128, 32, 32, strides=[131072, 1024, 32, 1], requires_grad=1, device=cpu) = onnx::Relu[onnx_name=\"/layer2/layer2.0/act1/Relu\"](%/layer2/layer2.0/conv1/Conv_output_0), scope: timm.models.resnet.ResNet::/torch.nn.modules.container.Sequential::layer2/timm.models.resnet.BasicBlock::layer2.0/torch.nn.modules.activation.ReLU::act1 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1455:0\n",
      "  %/layer2/layer2.0/conv2/Conv_output_0 : Float(*, 128, 32, 32, strides=[131072, 1024, 32, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name=\"/layer2/layer2.0/conv2/Conv\"](%/layer2/layer2.0/act1/Relu_output_0, %onnx::Conv_211, %onnx::Conv_212), scope: timm.models.resnet.ResNet::/torch.nn.modules.container.Sequential::layer2/timm.models.resnet.BasicBlock::layer2.0/torch.nn.modules.conv.Conv2d::conv2 # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:459:0\n",
      "  %/layer2/layer2.0/downsample/downsample.0/Conv_output_0 : Float(*, 128, 32, 32, strides=[131072, 1024, 32, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[2, 2], onnx_name=\"/layer2/layer2.0/downsample/downsample.0/Conv\"](%/layer1/layer1.1/act2/Relu_output_0, %onnx::Conv_214, %onnx::Conv_215), scope: timm.models.resnet.ResNet::/torch.nn.modules.container.Sequential::layer2/timm.models.resnet.BasicBlock::layer2.0/torch.nn.modules.container.Sequential::downsample/torch.nn.modules.conv.Conv2d::downsample.0 # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:459:0\n",
      "  %/layer2/layer2.0/Add_output_0 : Float(*, 128, 32, 32, strides=[131072, 1024, 32, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"/layer2/layer2.0/Add\"](%/layer2/layer2.0/conv2/Conv_output_0, %/layer2/layer2.0/downsample/downsample.0/Conv_output_0), scope: timm.models.resnet.ResNet::/torch.nn.modules.container.Sequential::layer2/timm.models.resnet.BasicBlock::layer2.0 # /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:115:0\n",
      "  %/layer2/layer2.0/act2/Relu_output_0 : Float(*, 128, 32, 32, strides=[131072, 1024, 32, 1], requires_grad=1, device=cpu) = onnx::Relu[onnx_name=\"/layer2/layer2.0/act2/Relu\"](%/layer2/layer2.0/Add_output_0), scope: timm.models.resnet.ResNet::/torch.nn.modules.container.Sequential::layer2/timm.models.resnet.BasicBlock::layer2.0/torch.nn.modules.activation.ReLU::act2 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1455:0\n",
      "  %/layer2/layer2.1/conv1/Conv_output_0 : Float(*, 128, 32, 32, strides=[131072, 1024, 32, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name=\"/layer2/layer2.1/conv1/Conv\"](%/layer2/layer2.0/act2/Relu_output_0, %onnx::Conv_217, %onnx::Conv_218), scope: timm.models.resnet.ResNet::/torch.nn.modules.container.Sequential::layer2/timm.models.resnet.BasicBlock::layer2.1/torch.nn.modules.conv.Conv2d::conv1 # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:459:0\n",
      "  %/layer2/layer2.1/act1/Relu_output_0 : Float(*, 128, 32, 32, strides=[131072, 1024, 32, 1], requires_grad=1, device=cpu) = onnx::Relu[onnx_name=\"/layer2/layer2.1/act1/Relu\"](%/layer2/layer2.1/conv1/Conv_output_0), scope: timm.models.resnet.ResNet::/torch.nn.modules.container.Sequential::layer2/timm.models.resnet.BasicBlock::layer2.1/torch.nn.modules.activation.ReLU::act1 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1455:0\n",
      "  %/layer2/layer2.1/conv2/Conv_output_0 : Float(*, 128, 32, 32, strides=[131072, 1024, 32, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name=\"/layer2/layer2.1/conv2/Conv\"](%/layer2/layer2.1/act1/Relu_output_0, %onnx::Conv_220, %onnx::Conv_221), scope: timm.models.resnet.ResNet::/torch.nn.modules.container.Sequential::layer2/timm.models.resnet.BasicBlock::layer2.1/torch.nn.modules.conv.Conv2d::conv2 # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:459:0\n",
      "  %/layer2/layer2.1/Add_output_0 : Float(*, 128, 32, 32, strides=[131072, 1024, 32, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"/layer2/layer2.1/Add\"](%/layer2/layer2.1/conv2/Conv_output_0, %/layer2/layer2.0/act2/Relu_output_0), scope: timm.models.resnet.ResNet::/torch.nn.modules.container.Sequential::layer2/timm.models.resnet.BasicBlock::layer2.1 # /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:115:0\n",
      "  %/layer2/layer2.1/act2/Relu_output_0 : Float(*, 128, 32, 32, strides=[131072, 1024, 32, 1], requires_grad=1, device=cpu) = onnx::Relu[onnx_name=\"/layer2/layer2.1/act2/Relu\"](%/layer2/layer2.1/Add_output_0), scope: timm.models.resnet.ResNet::/torch.nn.modules.container.Sequential::layer2/timm.models.resnet.BasicBlock::layer2.1/torch.nn.modules.activation.ReLU::act2 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1455:0\n",
      "  %/layer3/layer3.0/conv1/Conv_output_0 : Float(*, 256, 16, 16, strides=[65536, 256, 16, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[2, 2], onnx_name=\"/layer3/layer3.0/conv1/Conv\"](%/layer2/layer2.1/act2/Relu_output_0, %onnx::Conv_223, %onnx::Conv_224), scope: timm.models.resnet.ResNet::/torch.nn.modules.container.Sequential::layer3/timm.models.resnet.BasicBlock::layer3.0/torch.nn.modules.conv.Conv2d::conv1 # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:459:0\n",
      "  %/layer3/layer3.0/act1/Relu_output_0 : Float(*, 256, 16, 16, strides=[65536, 256, 16, 1], requires_grad=1, device=cpu) = onnx::Relu[onnx_name=\"/layer3/layer3.0/act1/Relu\"](%/layer3/layer3.0/conv1/Conv_output_0), scope: timm.models.resnet.ResNet::/torch.nn.modules.container.Sequential::layer3/timm.models.resnet.BasicBlock::layer3.0/torch.nn.modules.activation.ReLU::act1 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1455:0\n",
      "  %/layer3/layer3.0/conv2/Conv_output_0 : Float(*, 256, 16, 16, strides=[65536, 256, 16, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name=\"/layer3/layer3.0/conv2/Conv\"](%/layer3/layer3.0/act1/Relu_output_0, %onnx::Conv_226, %onnx::Conv_227), scope: timm.models.resnet.ResNet::/torch.nn.modules.container.Sequential::layer3/timm.models.resnet.BasicBlock::layer3.0/torch.nn.modules.conv.Conv2d::conv2 # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:459:0\n",
      "  %/layer3/layer3.0/downsample/downsample.0/Conv_output_0 : Float(*, 256, 16, 16, strides=[65536, 256, 16, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[2, 2], onnx_name=\"/layer3/layer3.0/downsample/downsample.0/Conv\"](%/layer2/layer2.1/act2/Relu_output_0, %onnx::Conv_229, %onnx::Conv_230), scope: timm.models.resnet.ResNet::/torch.nn.modules.container.Sequential::layer3/timm.models.resnet.BasicBlock::layer3.0/torch.nn.modules.container.Sequential::downsample/torch.nn.modules.conv.Conv2d::downsample.0 # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:459:0\n",
      "  %/layer3/layer3.0/Add_output_0 : Float(*, 256, 16, 16, strides=[65536, 256, 16, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"/layer3/layer3.0/Add\"](%/layer3/layer3.0/conv2/Conv_output_0, %/layer3/layer3.0/downsample/downsample.0/Conv_output_0), scope: timm.models.resnet.ResNet::/torch.nn.modules.container.Sequential::layer3/timm.models.resnet.BasicBlock::layer3.0 # /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:115:0\n",
      "  %/layer3/layer3.0/act2/Relu_output_0 : Float(*, 256, 16, 16, strides=[65536, 256, 16, 1], requires_grad=1, device=cpu) = onnx::Relu[onnx_name=\"/layer3/layer3.0/act2/Relu\"](%/layer3/layer3.0/Add_output_0), scope: timm.models.resnet.ResNet::/torch.nn.modules.container.Sequential::layer3/timm.models.resnet.BasicBlock::layer3.0/torch.nn.modules.activation.ReLU::act2 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1455:0\n",
      "  %/layer3/layer3.1/conv1/Conv_output_0 : Float(*, 256, 16, 16, strides=[65536, 256, 16, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name=\"/layer3/layer3.1/conv1/Conv\"](%/layer3/layer3.0/act2/Relu_output_0, %onnx::Conv_232, %onnx::Conv_233), scope: timm.models.resnet.ResNet::/torch.nn.modules.container.Sequential::layer3/timm.models.resnet.BasicBlock::layer3.1/torch.nn.modules.conv.Conv2d::conv1 # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:459:0\n",
      "  %/layer3/layer3.1/act1/Relu_output_0 : Float(*, 256, 16, 16, strides=[65536, 256, 16, 1], requires_grad=1, device=cpu) = onnx::Relu[onnx_name=\"/layer3/layer3.1/act1/Relu\"](%/layer3/layer3.1/conv1/Conv_output_0), scope: timm.models.resnet.ResNet::/torch.nn.modules.container.Sequential::layer3/timm.models.resnet.BasicBlock::layer3.1/torch.nn.modules.activation.ReLU::act1 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1455:0\n",
      "  %/layer3/layer3.1/conv2/Conv_output_0 : Float(*, 256, 16, 16, strides=[65536, 256, 16, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name=\"/layer3/layer3.1/conv2/Conv\"](%/layer3/layer3.1/act1/Relu_output_0, %onnx::Conv_235, %onnx::Conv_236), scope: timm.models.resnet.ResNet::/torch.nn.modules.container.Sequential::layer3/timm.models.resnet.BasicBlock::layer3.1/torch.nn.modules.conv.Conv2d::conv2 # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:459:0\n",
      "  %/layer3/layer3.1/Add_output_0 : Float(*, 256, 16, 16, strides=[65536, 256, 16, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"/layer3/layer3.1/Add\"](%/layer3/layer3.1/conv2/Conv_output_0, %/layer3/layer3.0/act2/Relu_output_0), scope: timm.models.resnet.ResNet::/torch.nn.modules.container.Sequential::layer3/timm.models.resnet.BasicBlock::layer3.1 # /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:115:0\n",
      "  %/layer3/layer3.1/act2/Relu_output_0 : Float(*, 256, 16, 16, strides=[65536, 256, 16, 1], requires_grad=1, device=cpu) = onnx::Relu[onnx_name=\"/layer3/layer3.1/act2/Relu\"](%/layer3/layer3.1/Add_output_0), scope: timm.models.resnet.ResNet::/torch.nn.modules.container.Sequential::layer3/timm.models.resnet.BasicBlock::layer3.1/torch.nn.modules.activation.ReLU::act2 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1455:0\n",
      "  %/layer4/layer4.0/conv1/Conv_output_0 : Float(*, 512, 8, 8, strides=[32768, 64, 8, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[2, 2], onnx_name=\"/layer4/layer4.0/conv1/Conv\"](%/layer3/layer3.1/act2/Relu_output_0, %onnx::Conv_238, %onnx::Conv_239), scope: timm.models.resnet.ResNet::/torch.nn.modules.container.Sequential::layer4/timm.models.resnet.BasicBlock::layer4.0/torch.nn.modules.conv.Conv2d::conv1 # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:459:0\n",
      "  %/layer4/layer4.0/act1/Relu_output_0 : Float(*, 512, 8, 8, strides=[32768, 64, 8, 1], requires_grad=1, device=cpu) = onnx::Relu[onnx_name=\"/layer4/layer4.0/act1/Relu\"](%/layer4/layer4.0/conv1/Conv_output_0), scope: timm.models.resnet.ResNet::/torch.nn.modules.container.Sequential::layer4/timm.models.resnet.BasicBlock::layer4.0/torch.nn.modules.activation.ReLU::act1 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1455:0\n",
      "  %/layer4/layer4.0/conv2/Conv_output_0 : Float(*, 512, 8, 8, strides=[32768, 64, 8, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name=\"/layer4/layer4.0/conv2/Conv\"](%/layer4/layer4.0/act1/Relu_output_0, %onnx::Conv_241, %onnx::Conv_242), scope: timm.models.resnet.ResNet::/torch.nn.modules.container.Sequential::layer4/timm.models.resnet.BasicBlock::layer4.0/torch.nn.modules.conv.Conv2d::conv2 # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:459:0\n",
      "  %/layer4/layer4.0/downsample/downsample.0/Conv_output_0 : Float(*, 512, 8, 8, strides=[32768, 64, 8, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[2, 2], onnx_name=\"/layer4/layer4.0/downsample/downsample.0/Conv\"](%/layer3/layer3.1/act2/Relu_output_0, %onnx::Conv_244, %onnx::Conv_245), scope: timm.models.resnet.ResNet::/torch.nn.modules.container.Sequential::layer4/timm.models.resnet.BasicBlock::layer4.0/torch.nn.modules.container.Sequential::downsample/torch.nn.modules.conv.Conv2d::downsample.0 # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:459:0\n",
      "  %/layer4/layer4.0/Add_output_0 : Float(*, 512, 8, 8, strides=[32768, 64, 8, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"/layer4/layer4.0/Add\"](%/layer4/layer4.0/conv2/Conv_output_0, %/layer4/layer4.0/downsample/downsample.0/Conv_output_0), scope: timm.models.resnet.ResNet::/torch.nn.modules.container.Sequential::layer4/timm.models.resnet.BasicBlock::layer4.0 # /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:115:0\n",
      "  %/layer4/layer4.0/act2/Relu_output_0 : Float(*, 512, 8, 8, strides=[32768, 64, 8, 1], requires_grad=1, device=cpu) = onnx::Relu[onnx_name=\"/layer4/layer4.0/act2/Relu\"](%/layer4/layer4.0/Add_output_0), scope: timm.models.resnet.ResNet::/torch.nn.modules.container.Sequential::layer4/timm.models.resnet.BasicBlock::layer4.0/torch.nn.modules.activation.ReLU::act2 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1455:0\n",
      "  %/layer4/layer4.1/conv1/Conv_output_0 : Float(*, 512, 8, 8, strides=[32768, 64, 8, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name=\"/layer4/layer4.1/conv1/Conv\"](%/layer4/layer4.0/act2/Relu_output_0, %onnx::Conv_247, %onnx::Conv_248), scope: timm.models.resnet.ResNet::/torch.nn.modules.container.Sequential::layer4/timm.models.resnet.BasicBlock::layer4.1/torch.nn.modules.conv.Conv2d::conv1 # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:459:0\n",
      "  %/layer4/layer4.1/act1/Relu_output_0 : Float(*, 512, 8, 8, strides=[32768, 64, 8, 1], requires_grad=1, device=cpu) = onnx::Relu[onnx_name=\"/layer4/layer4.1/act1/Relu\"](%/layer4/layer4.1/conv1/Conv_output_0), scope: timm.models.resnet.ResNet::/torch.nn.modules.container.Sequential::layer4/timm.models.resnet.BasicBlock::layer4.1/torch.nn.modules.activation.ReLU::act1 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1455:0\n",
      "  %/layer4/layer4.1/conv2/Conv_output_0 : Float(*, 512, 8, 8, strides=[32768, 64, 8, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name=\"/layer4/layer4.1/conv2/Conv\"](%/layer4/layer4.1/act1/Relu_output_0, %onnx::Conv_250, %onnx::Conv_251), scope: timm.models.resnet.ResNet::/torch.nn.modules.container.Sequential::layer4/timm.models.resnet.BasicBlock::layer4.1/torch.nn.modules.conv.Conv2d::conv2 # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/conv.py:459:0\n",
      "  %/layer4/layer4.1/Add_output_0 : Float(*, 512, 8, 8, strides=[32768, 64, 8, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"/layer4/layer4.1/Add\"](%/layer4/layer4.1/conv2/Conv_output_0, %/layer4/layer4.0/act2/Relu_output_0), scope: timm.models.resnet.ResNet::/torch.nn.modules.container.Sequential::layer4/timm.models.resnet.BasicBlock::layer4.1 # /usr/local/lib/python3.8/dist-packages/timm/models/resnet.py:115:0\n",
      "  %/layer4/layer4.1/act2/Relu_output_0 : Float(*, 512, 8, 8, strides=[32768, 64, 8, 1], requires_grad=1, device=cpu) = onnx::Relu[onnx_name=\"/layer4/layer4.1/act2/Relu\"](%/layer4/layer4.1/Add_output_0), scope: timm.models.resnet.ResNet::/torch.nn.modules.container.Sequential::layer4/timm.models.resnet.BasicBlock::layer4.1/torch.nn.modules.activation.ReLU::act2 # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1455:0\n",
      "  %/global_pool/pool/GlobalAveragePool_output_0 : Float(*, 512, 1, 1, strides=[512, 1, 1, 1], requires_grad=1, device=cpu) = onnx::GlobalAveragePool[onnx_name=\"/global_pool/pool/GlobalAveragePool\"](%/layer4/layer4.1/act2/Relu_output_0), scope: timm.models.resnet.ResNet::/timm.layers.adaptive_avgmax_pool.SelectAdaptivePool2d::global_pool/torch.nn.modules.pooling.AdaptiveAvgPool2d::pool # /usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:1214:0\n",
      "  %/global_pool/flatten/Flatten_output_0 : Float(*, 512, strides=[512, 1], requires_grad=1, device=cpu) = onnx::Flatten[axis=1, onnx_name=\"/global_pool/flatten/Flatten\"](%/global_pool/pool/GlobalAveragePool_output_0), scope: timm.models.resnet.ResNet::/timm.layers.adaptive_avgmax_pool.SelectAdaptivePool2d::global_pool/torch.nn.modules.flatten.Flatten::flatten # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/flatten.py:46:0\n",
      "  %output : Float(*, 17, strides=[17, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1, onnx_name=\"/fc/Gemm\"](%/global_pool/flatten/Flatten_output_0, %fc.weight, %fc.bias), scope: timm.models.resnet.ResNet::/torch.nn.modules.linear.Linear::fc # /usr/local/lib/python3.8/dist-packages/torch/nn/modules/linear.py:114:0\n",
      "  return (%output)\n",
      "\n",
      "=========== Diagnostic Run torch.onnx.export version 2.1.0a0+fe05266 ===========\n",
      "verbose: False, log level: Level.ERROR\n",
      "======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "th.onnx.export(\n",
    "    model_torch.model,\n",
    "    th.rand(1, 3, MAX_UINT8, MAX_UINT8).to(th.float32),\n",
    "    \"weights/model.onnx\",\n",
    "    verbose=True,\n",
    "    input_names=['input'],\n",
    "    output_names=['output'],\n",
    "    dynamic_axes = {\n",
    "        'input': [0], \n",
    "        'output': [0]\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "692d0ae5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-21 22:23:22.976463627 [W:onnxruntime:Default, onnxruntime_pybind_state.cc:541 CreateExecutionProviderInstance] Failed to create CUDAExecutionProvider. Please reference https://onnxruntime.ai/docs/reference/execution-providers/CUDA-ExecutionProvider.html#requirements to ensure all dependencies are met.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>platform</th>\n",
       "      <th>batch_sz</th>\n",
       "      <th>tool</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.018136</td>\n",
       "      <td>1GPU</td>\n",
       "      <td>1</td>\n",
       "      <td>TorchTrace</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.018139</td>\n",
       "      <td>1GPU</td>\n",
       "      <td>2</td>\n",
       "      <td>TorchTrace</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.018288</td>\n",
       "      <td>1GPU</td>\n",
       "      <td>4</td>\n",
       "      <td>TorchTrace</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.018123</td>\n",
       "      <td>1GPU</td>\n",
       "      <td>8</td>\n",
       "      <td>TorchTrace</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.017804</td>\n",
       "      <td>1GPU</td>\n",
       "      <td>16</td>\n",
       "      <td>TorchTrace</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       time platform  batch_sz        tool\n",
       "0  0.018136     1GPU         1  TorchTrace\n",
       "1  0.018139     1GPU         2  TorchTrace\n",
       "2  0.018288     1GPU         4  TorchTrace\n",
       "3  0.018123     1GPU         8  TorchTrace\n",
       "4  0.017804     1GPU        16  TorchTrace"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"./config/onnx_gpu.yaml\") as fp:\n",
    "    cfg_onnx = yaml.safe_load(fp)\n",
    "cfg_onnx[\"device\"] = DEVICE\n",
    "model_onnx = ModelONNX(cfg_onnx)\n",
    "records = []\n",
    "for batch_sz in BATCH_SIZES:\n",
    "    avg, _ = benchmark(\n",
    "        model=model_onnx,\n",
    "        input_shape=(batch_sz, 3, MAX_UINT8, MAX_UINT8),\n",
    "        nwarmup=WARMUP,\n",
    "        nruns=N_RUNS,\n",
    "        print_step=N_PRINT,\n",
    "        verbose=VERBOSE\n",
    "    )\n",
    "    records.append(\n",
    "        {\n",
    "            \"time\": avg,\n",
    "            \"platform\": PLATFORM, \n",
    "            \"batch_sz\": batch_sz,\n",
    "            \"tool\": \"TorchTrace\"\n",
    "        }\n",
    "    )\n",
    "inference_records.extend(records)\n",
    "pd.DataFrame(records)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8132d86a",
   "metadata": {},
   "source": [
    "### OpenVino Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16f2f502",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bash command to convert ONNX -> OpenVino\n",
    "!mo --input_model weights/model.onnx --output_dir weights/openvino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fc89ee47",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'openvino'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mopen_vino\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ModelOpenVino\n",
      "File \u001b[0;32m/workspace/project/src/model/open_vino.py:3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtp\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mopenvino\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mruntime\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Core\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mModelOpenVino\u001b[39;00m:\n\u001b[1;32m      7\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;124;03m    Class for saving and loading modelss\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'openvino'"
     ]
    }
   ],
   "source": [
    "from src.model.open_vino import ModelOpenVino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d83ba716",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./config/onnx_gpu.yaml\") as fp:\n",
    "    cfg_ov = yaml.safe_load(fp)\n",
    "cfg_ov[\"device\"] = DEVICE\n",
    "\n",
    "model_ov = ModelOpenVino(cfg_ov)\n",
    "records = []\n",
    "for batch_sz in BATCH_SIZES:\n",
    "    avg, _ = benchmark(\n",
    "        model=model_ov,\n",
    "        input_shape=(batch_sz, 3, MAX_UINT8, MAX_UINT8),\n",
    "        nwarmup=WARMUP,\n",
    "        nruns=N_RUNS,\n",
    "        print_step=N_PRINT,\n",
    "        verbose=VERBOSE\n",
    "    )\n",
    "    records.append(\n",
    "        {\n",
    "            \"time\": avg,\n",
    "            \"platform\": PLATFORM, \n",
    "            \"batch_sz\": batch_sz,\n",
    "            \"tool\": \"TorchTrace\"\n",
    "        }\n",
    "    )\n",
    "inference_records.extend(records)\n",
    "pd.DataFrame(records)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b57c417",
   "metadata": {},
   "source": [
    "### TensorRT32 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9e137d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorrt as trt\n",
    "import torch_tensorrt\n",
    "from src.model.torch_jit import ModelTorchJIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "069e38d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "trt_model = torch_tensorrt.compile(\n",
    "    model_torch.model,                                       \n",
    "    inputs = [torch_tensorrt.Input((1, 3, MAX_UINT8, MAX_UINT8))], \n",
    "    enabled_precisions = th.float32,                # <- изменения здесь\n",
    "    workspace_size = 1 << 30,                     \n",
    ")\n",
    "th.jit.save(trt_model, \"weights/model_trt_fp32.ts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5a59a9f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.004198403358459473, 0.00020665497439227944)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"./config/tensorrt_fp32.yaml\") as fp:\n",
    "    cfg_trt = yaml.safe_load(fp)\n",
    "cfg_trt[\"device\"] = DEVICE\n",
    "model_trt = ModelTorchJIT(cfg_trt)\n",
    "records = []\n",
    "for batch_sz in BATCH_SIZES:\n",
    "    avg, _ = benchmark(\n",
    "        model=model_trt,\n",
    "        input_shape=(batch_sz, 3, MAX_UINT8, MAX_UINT8),\n",
    "        nwarmup=WARMUP,\n",
    "        nruns=N_RUNS,\n",
    "        print_step=N_PRINT,\n",
    "        verbose=VERBOSE\n",
    "    )\n",
    "    records.append(\n",
    "        {\n",
    "            \"time\": avg,\n",
    "            \"platform\": PLATFORM, \n",
    "            \"batch_sz\": batch_sz,\n",
    "            \"tool\": \"TensorRT32\"\n",
    "        }\n",
    "    )\n",
    "inference_records.extend(records)\n",
    "pd.DataFrame(records)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a179765",
   "metadata": {},
   "source": [
    "### TensorRT16 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1c5cd16f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorrt as trt\n",
    "import torch_tensorrt\n",
    "from src.model.torch_jit import ModelTorchJIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c6d72a4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: [Torch-TensorRT] - Dilation not used in Max pooling converter\n",
      "WARNING: [Torch-TensorRT TorchScript Conversion Context] - TensorRT encountered issues when converting weights between types and that could affect accuracy.\n",
      "WARNING: [Torch-TensorRT TorchScript Conversion Context] - If this is not the desired behavior, please modify the weights or retrain with regularization to adjust the magnitude of the weights.\n",
      "WARNING: [Torch-TensorRT TorchScript Conversion Context] - Check verbose logs for the list of affected weights.\n",
      "WARNING: [Torch-TensorRT TorchScript Conversion Context] - - 29 weights are affected by this issue: Detected subnormal FP16 values.\n",
      "WARNING: [Torch-TensorRT TorchScript Conversion Context] - - 15 weights are affected by this issue: Detected values less than smallest positive FP16 subnormal value and converted them to the FP16 minimum subnormalized value.\n"
     ]
    }
   ],
   "source": [
    "trt_model = torch_tensorrt.compile(\n",
    "    model_torch.model,                                       \n",
    "    inputs = [torch_tensorrt.Input((1, 3, MAX_UINT8, MAX_UINT8))], \n",
    "    enabled_precisions = th.float16,                # <- изменения здесь\n",
    "    workspace_size = 1 << 30,                     \n",
    ")\n",
    "th.jit.save(trt_model, \"weights/model_trt_fp16.ts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "296491c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0028227734565734863, 4.588646928421068e-05)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"./config/tensorrt_fp16.yaml\") as fp:\n",
    "    cfg_trt = yaml.safe_load(fp)\n",
    "cfg_trt[\"device\"] = DEVICE\n",
    "model_trt = ModelTorchJIT(cfg_trt)\n",
    "records = []\n",
    "for batch_sz in BATCH_SIZES:\n",
    "    avg, _ = benchmark(\n",
    "        model=model_trt,\n",
    "        input_shape=(batch_sz, 3, MAX_UINT8, MAX_UINT8),\n",
    "        nwarmup=WARMUP,\n",
    "        nruns=N_RUNS,\n",
    "        print_step=N_PRINT,\n",
    "        verbose=VERBOSE\n",
    "    )\n",
    "    records.append(\n",
    "        {\n",
    "            \"time\": avg,\n",
    "            \"platform\": PLATFORM, \n",
    "            \"batch_sz\": batch_sz,\n",
    "            \"tool\": \"TensorRT32\"\n",
    "        }\n",
    "    )\n",
    "inference_records.extend(records)\n",
    "pd.DataFrame(records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dcae0f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\n",
    "    \"results/inference_results_1gpu.json\", \n",
    "    \"w\",\n",
    "    encoding=\"utf8\"\n",
    ") as fp:\n",
    "    json.dump(fp=fp, obj=inference_records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8924d96b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
